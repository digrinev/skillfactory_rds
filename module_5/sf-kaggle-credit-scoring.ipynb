{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Спасибо ребятам из команды Sokolov и Golobokov за идею оформления ноутбука"},{"metadata":{},"cell_type":"markdown","source":"# 1. Загрузка необходимых библиотек"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler, OrdinalEncoder, MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score, roc_curve, \\\n                            plot_confusion_matrix, precision_recall_curve, auc, plot_precision_recall_curve, average_precision_score\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nimport category_encoders as ce\nfrom mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\nfrom math import log as log\nimport os\n\n# Загрузка данных Kaggle\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nPATH_to_file = '/kaggle/input/sf-dst-scoring/'\n\n# Загружаем дополнительные функции\n\n# Plot Boxplots\ndef plot_outliers(df, width=20, height=10):\n    '''\n    df - Pandas DataFrame\n    width - Figure width\n    height - Figure height\n    '''\n    fig = plt.figure(figsize=(width, height))\n    sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n    plt.show()\n    \n\n# Plot BoxPlots compare to target class\ndef plot_boxplots(df, columns, target, nrows=2, ncols=2, figsize=(15,15)):\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    plt.subplots_adjust(wspace = 0.5)\n    axes = axes.flatten()\n    for i in range(len(columns)):\n        sns.boxplot(x=\"default\", y=columns[i], data=df, orient = 'v', ax=axes[i], showfliers=True)\n        \ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5, use_abs=True, target=None, filter_target=False):\n    '''\n    df - Pandas DataFrame\n    n - number of return values\n    use_abs - use absolute numbers\n    target - feature name to return\n    filter_target - use feature filter\n    '''\n    \n    if use_abs:\n        au_corr = df.corr().abs().unstack()\n    else:\n        au_corr = df.corr().unstack()\n        \n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    \n    if filter_target and target is not None:\n        return au_corr.filter(like=target, axis=0)[0:n]\n    \n    return au_corr[0:n]\n\n\n# Посчитаем важность признаков при помощи однофакторного дисперсионного анализа (ANOVA)\ndef plot_fclassif(df, columns, target):\n    '''\n    sklean.feature_selection.f_classif wrapper\n    ------------------------------------------\n    df - Pandas DataFrame\n    columns - numerical features\n    target - Our target feature\n    '''\n    \n    if df is not None and columns is not None and target is not None:\n        imp_num = pd.Series(f_classif(df[columns], df[target])[0], index = columns)\n        imp_num.sort_values(inplace = True)\n        imp_num.plot(kind = 'barh')\n    else:\n        raise Exception('Fill params!')\n\n\ndef plot_mutual_info_classif(df, columns, target):\n    '''\n    sklean.feature_selection.mutual_info_classif\n    ------------------------------------------\n    df - Pandas DataFrame\n    columns - binary, categorical features\n    target - Our target feature\n    '''\n    if df is not None and columns is not None and target is not None:\n        imp_cat = pd.Series(mutual_info_classif(df[columns], df[target],\n                                            discrete_features =True), index = columns)\n        imp_cat.sort_values(inplace = True)\n        imp_cat.plot(kind = 'barh')\n    else:\n        raise Exception('Fill params!')\n        \n# Отрисовать ROC кривую\ndef roc_auc_plot(y_true, y_pred_proba):\n    '''\n    Функция считает AUC и отрисовывает ROC кривую:\n        y_true - истинное значение класса\n        y_pred_proba - предсказанная вероятность класса [:, 1]\n    '''\n    # Посчитать значения ROC кривой и значение площади под кривой AUC\n    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n    roc_auc = roc_auc_score(y_true, y_pred_proba)\n    \n    plt.figure()\n    plt.plot([0, 1], label='Baseline', linestyle='--')\n    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n    plt.title('ROC AUC = %0.3f' % roc_auc, fontsize=15)\n    plt.xlabel('False positive rate (FPR)', fontsize=15)\n    plt.ylabel('True positive rate (TPR)', fontsize=15)\n    plt.legend(fontsize=15, loc = 'lower right')\n\n# Выводим распределение переменной и ее логарифма\ndef plot_dist_log(df, column, nrows=1, ncols=2, figsize=(15,15)):\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    plt.subplots_adjust(wspace = 0.5)\n    axes = axes.flatten()\n    axes[0].title.set_text(column)\n    axes[1].title.set_text('np.log('+column+')')\n    sns.distplot(df[column], ax=axes[0], axlabel=False, kde=False)\n    sns.distplot(np.log(df[column] + 1), ax=axes[1], axlabel=False, kde=False)\n    fig.suptitle(f'Распределение признака {column} и np.log({column})', fontsize=16, y=1.12)\n    \n    # Выводим дополнительную информацию о признаке\n    feature_info = dict(count=df[column].count(), nan=df[column].isnull().sum(), \n                    min=df[column].min(), max=df[column].max(), median=df[column].median(), mean=df[column].mean())\n\n    fi = pd.Series(feature_info)\n    p = pd.DataFrame(fi, columns=[column])\n\n    display(p)\n\n# Выводим метрики модели\ndef show_model_metrics(y_true, y_pred, y_probs):\n    print(f'f1_score: {f1_score(y_true, y_pred)}')\n    print(f'precision_score: {precision_score(y_true, y_pred)}')\n    print(f'recall_score: {recall_score(y_true, y_pred)}')\n    print(f'roc_auc: {roc_auc_score(y_true, y_probs)}')\n    \n    \n# Выводим PRC-AUC\ndef plot_prc_auc(model, X, y, y_prob):\n    average_precision = average_precision_score(y, y_prob)\n    disp = plot_precision_recall_curve(model, X, y)\n    disp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))\n    \n# Нарисовать кросс-валидацию\ndef plot_crossval_score(cross_val, metric, figsize=(20, 10)):\n    plt.figure(figsize=figsize)\n    sns.lineplot(data=cross_val, x=range(len(cross_val['score_time'])), y=\"test_score\", legend='full', label='тестовая выборка')\n    sns.lineplot(data=cross_val, x=range(len(cross_val['score_time'])), y=\"train_score\", legend='full', label='тренировочная выборка')\n    sns.lineplot(data=cross_val, x=range(len(cross_val['score_time'])), y=np.mean(cross_val['test_score']), label='среднее значение на тесте')\n    sns.lineplot(data=cross_val, x=range(len(cross_val['score_time'])), y=np.mean(cross_val['train_score']), legend='full', label='среднее значение на трейне')\n    plt.xlabel(\"Номер фолда\")\n    plt.ylabel(metric)\n    plt.title(f\"Кросс-валидация по ROC-AUC (KFold={len(cross_val['score_time'])})\")\n\ndef prepare_data(df):\n    # Готовим данные для обучения модели\n    train_data = df[df.Train == 1].drop(['Train'], axis=1)\n    test_data = df[df.Train == 0].drop(['Train'], axis=1)\n\n    y = train_data.default.values\n    X = train_data.drop(['default'], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n    \n    return X_train, X_test, y_train, y_test\n\n\n# Удаляем выбросы в датасете \ndef remove_outliers_irq_dataset(df, iqr_detect=1.5):\n    '''\n    df - Pandas DataFrame\n    iqr_detect - IQR to detect and filter outliers. Default: 1.5 \n    '''\n    \n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n\n    return df[~((df < (Q1 - iqr_detect * IQR)) |(df > (Q3 + iqr_detect * IQR))).any(axis=1)]\n\n# Удаляем выбросы по конкретному признаку\ndef remove_outliers_iqr_column(df_in, col_name):\n    '''\n    df_in - Pandas DataFrame\n    col_name - DataFrame column to detect outliers\n    '''\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    \n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    \n    return df_out\n\n# Загузка данных с обработкой признаков\ndef load_data(fill_na='popular', preprocess=False, drop_outliers=False, outliers_column=None, log_numerical=True):\n    '''load_data - загружает данных и возвращает обработанный Pandas DataFrame\n        fill_na - как заполнять пропущенные значения [mean, mode, drop]\n        preprocess - выполнять или нет ручную обработку данных [False если используется pipeline]\n        drop_outliers - удалять выбросы или нет \n        log_numerical - логарифмировать числовые признаки или нет\n    '''\n    df_train = pd.read_csv(PATH_to_file+'train.csv')\n    df_test = pd.read_csv(PATH_to_file+'test.csv')\n    \n    df_train['Train'] = 1 # трэйн\n    df_test['Train'] = 0 # тест\n\n    df = df_train.append(df_test, sort=False).reset_index(drop=True) # объединяем\n    \n    # внесем данные из резюме в списки \n    time_cols = ['app_date']\n    # бинарные переменные\n    bin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport', 'default_peak', 'normal_age']\n    # категориальные переменные\n    cat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\n    # числовые переменные\n    num_cols = ['client_id', 'age','decline_app_cnt','score_bki','bki_request_cnt','income','days_between_firstdate', 'mean_region_bki'] # days_between_firstdate - признак добавим позже, как разницу между\n       \n    # Логарифмируем переменные\n    if log_numerical:\n        df['age'] = np.log(df['age'] + 1)\n        df['decline_app_cnt'] = np.log(df['decline_app_cnt'] + 1)\n        df['bki_request_cnt'] = np.log(df['bki_request_cnt'] + 1)\n        df['income'] = np.log(df['income'] + 1)\n    \n    # Дата\n    df.app_date = pd.to_datetime(df.app_date, format='%d%b%Y')\n    \n    # Посмотрим на максимальное и минимальное значение\n    start_date = df.app_date.min()\n    end_date = df.app_date.max()\n    \n    # Создадим новый признак - номер дня от минимальной даты\n    df['days_between_firstdate'] = (df.app_date - start_date).dt.days.astype('int')\n    \n    # Признак, когда дефолт идет на спад\n    df['default_peak'] = (df.days_between_firstdate > 90).astype('int')\n    \n    # Средний score_bki по региону\n#     mean_score_bki = df.groupby('region_rating')['score_bki'].mean().to_dict()\n#     df['mean_region_bki'] = df.apply(lambda x: x.score_bki / mean_score_bki[x.region_rating], axis=1)\n    \n    # Обычно благоприятный возраст для кредита 30-40 лет\n    df['normal_age'] = ((df.age >= 30) & (df.age <= 40)).astype('int')\n    \n    # Ручная обработка данных\n    if preprocess:\n        labelEncoder = LabelEncoder()\n\n        # Закодируем бинарные признаки\n        for column in bin_cols:\n            df[column] = labelEncoder.fit_transform(df[column])\n\n        # Закодируем признак education, но сперва заполним пропуски самым частым значением\n        # Заполним пропуски\n        if fill_na in ['mean', 'mode', 'drop']:\n            if fill_na == 'mean':\n                df.education = df.education.fillna(df.education.value_counts()\n                                [df.education.value_counts() == int(df.education.value_counts().median())].index[0])\n            elif fill_na == 'mode':\n                df.education = df.education.fillna(df.education.mode()[0])\n            elif fill_na == 'drop':\n                df = df.dropna(axis=0)\n        else:\n            df.education = df.education.fillna('SCH')\n\n        # Закодируем признак образования\n        df.education = labelEncoder.fit_transform(df.education)\n\n        # Категориальные признаки в дамми переменные\n        df = pd.get_dummies(df, columns=cat_cols)\n        \n    df.drop('app_date', axis=1, inplace=True)\n    \n    # Удаляем выбросы\n    if drop_outliers and outliers_column is not None:\n        return remove_outliers_iqr_column(df, outliers_column)\n    \n    return df   \n\n# Пайплайн обработки данных\ndef prepare_data_pipeline(scaler='standard', polynomial_features=False, polynomial_n=2):\n    # бинарные переменные\n    bin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport', 'default_peak', 'normal_age']\n    # категориальные переменные\n    cat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\n    # числовые переменные\n    num_cols = ['client_id', 'age','decline_app_cnt','score_bki','bki_request_cnt','income','days_between_firstdate'] # days_between_firstdate - признак добавим позже, как разницу между\n    # Фичи для полиномизации\n    poly_cols = ['decline_app_cnt', 'score_bki', 'bki_request_cnt']\n    \n    bin_transformer = make_pipeline(OrdinalEncoder())\n    cat_transformer = make_pipeline(SimpleImputer(strategy='most_frequent', missing_values=np.nan), OrdinalEncoder(), OneHotEncoder())\n    poly_transformer = make_pipeline(PolynomialFeatures(polynomial_n))\n    \n    if scaler == 'standard':\n        num_transformer = make_pipeline(StandardScaler())\n    elif scaler == 'robust':\n        num_transformer = make_pipeline(RobustScaler())\n    elif scaler == 'minmax':\n        num_transformer = make_pipeline(MinMaxScaler())\n    else:\n        num_transformer = make_pipeline(StandardScaler())\n        \n    if polynomial_features:\n        transformers = [\n                        ('bin', bin_transformer, bin_cols),\n                        ('cat', cat_transformer, cat_cols),\n                        ('num', num_transformer, num_cols),\n                        ('poly', poly_transformer, poly_cols)\n        ]\n    else:\n        transformers = [\n                        ('bin', bin_transformer, bin_cols),\n                        ('cat', cat_transformer, cat_cols),\n                        ('num', num_transformer, num_cols),                    \n        ]\n    \n    return ColumnTransformer(transformers=transformers, remainder='passthrough')\n\n\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Генератор стандартных фич\nclass FeatureGenerator(BaseEstimator, TransformerMixin):\n\n    def __init__(self, feature_list = None, primitives=['mul']):\n        self.feature_list = feature_list\n        self.used_features = []\n        self.primitives = primitives\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        X_ = X.copy() # работаем с копией, чтобы не изменять оригинальный датасет\n        self.used_features = []  # обнуляем список использованных фич перед каждым вызовом transform\n\n        if self.feature_list is None:\n            self.feature_list = X_.columns\n\n        return self.feature_generator(X_)\n    \n    def feature_generator(self, X):\n        # Перебираем наши признаки и генерируем новые\n        for i, feature in enumerate(self.feature_list):\n            # Добавяем признак в список использованных\n            self.used_features.append(feature)\n            # Генерируем новые признаки по списку оставшихся\n            for feature_ in list(set(self.feature_list) - set(self.used_features)):\n                if self.primitives == 'all':\n                    self.primitives = ['mul', 'sum', 'sub', 'div', 'mean', 'std', 'median']\n                for primitive in self.primitives:\n                    feature_name = f'{feature}_{primitive}_{feature_}'\n                    if primitive == 'mul':\n                        X[feature_name] = X[feature] * X[feature_]\n                    if primitive == 'sum':\n                        X[feature_name] = X[feature] + X[feature_]\n                    if primitive == 'sub':\n                        X[feature_name] = X[feature] - X[feature_]\n                    if primitive == 'div':\n                        X[feature_name] = X[feature] / (X[feature_]+1)\n                    if primitive == 'mean':\n                        X[feature_name] = X[feature] / (X[feature_].mean() + 1)\n                    if primitive == 'std':\n                        X[feature_name] = X[feature] / (X[feature_].std() + 1)\n                    if primitive == 'median':\n                        X[feature_name] = X[feature] / (X[feature_].median() + 1)\n                    \n        return X\n    ","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/sf-dst-scoring/train.csv\n/kaggle/input/sf-dst-scoring/test.csv\n/kaggle/input/sf-dst-scoring/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42\n!pip freeze > requirements.txt\nCURRENT_DATE = pd.to_datetime('26/10/2020')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Загрузка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(PATH_to_file+'train.csv')\ndf_test = pd.read_csv(PATH_to_file+'test.csv')\npd.set_option('display.max_columns', None)\nprint('Размерность тренировочного датасета: ', df_train.shape)\ndisplay(df_train.head())\nprint('Размерность тестового датасета: ', df_test.shape)\ndisplay(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выполняем объединение датасетов в один\ndf_train['Train'] = 1 # трэйн\ndf_test['Train'] = 0 # тест\n\ndf = df_train.append(df_test, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Выполняем EDA"},{"metadata":{},"cell_type":"markdown","source":"Описания полей датасета\n\n* client_id - идентификатор клиента\n* education - уровень образования\n* sex - пол заемщика\n* age - возраст заемщика\n* car - флаг наличия автомобиля\n* car_type - флаг автомобиля иномарки\n* decline_app_cnt - количество отказанных прошлых заявок\n* good_work - флаг наличия “хорошей” работы\n* bki_request_cnt - количество запросов в БКИ\n* home_address - категоризатор домашнего адреса\n* work_address - категоризатор рабочего адреса\n* income - доход заемщика\n* foreign_passport - наличие загранпаспорта\n* sna - связь заемщика с клиентами банка\n* first_time - давность наличия информации о заемщике\n* score_bki - скоринговый балл по данным из БКИ\n* region_rating - рейтинг региона\n* app_date - дата подачи заявки\n* default - флаг дефолта по кредиту"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим дополнительную информацию по датасету\n\nprint(f'Размер обучающей выборки: {df_train.shape}, размер тестовой выборки: {df_test.shape}')\n\n# Количество уникальных значений\nfor column in df.columns:\n    print(f'{column} = {len(df[column].unique())}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По данным видим, что у нас имеется 1 признак - временной, 5 бинарных, 6 категориальных и 6 числовых."},{"metadata":{"trusted":true},"cell_type":"code","source":"# внесем данные из резюме в списки \ntime_cols = ['app_date']\n# бинарные переменные\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\n# категориальные переменные\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\n# числовые переменные\nnum_cols = ['client_id', 'age','decline_app_cnt','score_bki','bki_request_cnt','income','days_between_firstdate'] # days_between_firstdate - признак добавим позже, как разницу между минимальным app_date и app_date ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на пропуски\nimport missingno as msno\nmsno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Как видим, присутствует некоторое количество пропусков в признаке education. Позже мы их заполним различными способами."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на нашу целевую переменную\nsns.countplot(x='default', data=df)\ndisplay(df.default.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим,что у нас сильно несбалансированная выборка, что может привести к неудовлетворительным результатам при обучении логистической регрессии."},{"metadata":{},"cell_type":"markdown","source":"# 4 Посмотрим на признаки"},{"metadata":{},"cell_type":"markdown","source":"## age"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'age', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**age** - берем логарифмированный признак в работу"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'] = np.log(df['age'] + 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## decline_app_cnt"},{"metadata":{"trusted":true},"cell_type":"code","source":"#'age','decline_app_cnt','score_bki','bki_request_cnt','income'\nplot_dist_log(df[df.Train==1], 'decline_app_cnt', figsize=(8,4))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**decline_app_cnt**: логарифмирование особо не помогло, тем не менее оставим его в модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['decline_app_cnt'] = np.log(df['decline_app_cnt'] + 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## score_bki"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'score_bki', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**score_bki** распределение изначально нормальное. Логарифмирование смещает распределение вправо. Оставим признак как есть."},{"metadata":{},"cell_type":"markdown","source":"## bki_request_cnt"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'bki_request_cnt', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**bki_request_cnt** оставим логарифмированное распределение."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bki_request_cnt'] = np.log(df['bki_request_cnt'] + 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## income"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'income', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**income** логарифмированное распределение стало похоже на нормальное. Оставим в этом виде."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['income'] = np.log(df['income'] + 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Категориальные признаки\nПосмотрим на 'education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time'"},{"metadata":{},"cell_type":"markdown","source":"## education"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='education', data=df[df.Train==1], hue='education')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## region_rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'region_rating', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**region_rating** распределение похоже на нормальное. Посмотрим как модель поведет себя при обучение и примем решение о логарифмировании."},{"metadata":{},"cell_type":"markdown","source":"## home_address"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'home_address', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**home_address** имеет 3 категории. Оставляем как есть."},{"metadata":{},"cell_type":"markdown","source":"## work_address"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'work_address', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**work_address** аналогично home_address"},{"metadata":{},"cell_type":"markdown","source":"## sna"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'sna', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**sna** видим, что распределение смещено вправо. Логарифмирование не вносит значительных изменений. Оставим как есть.  "},{"metadata":{},"cell_type":"markdown","source":"## first_time"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df[df.Train==1], 'first_time', figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**first_time** нормальное распределение смещено влево. Оставляем как есть."},{"metadata":{},"cell_type":"markdown","source":"## app_date"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем признак в дату\ndf.app_date = pd.to_datetime(df.app_date, format='%d%b%Y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на максимальное и минимальное значение\nstart_date = df.app_date.min()\nend_date = df.app_date.max()\n\nprint(start_date, end_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим новый признак - номер дня от минимальной даты\ndf['days_between_firstdate'] = (df.app_date - start_date).dt.days.astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим как меняется распределение по дням в зависимости от дефолта"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df[(df.Train==1)]\nsns.distplot(train_df[train_df.default==0].days_between_firstdate, hist=False, rug=True)\nsns.distplot(train_df[train_df.default==1].days_between_firstdate, hist=False, rug=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из графика видно, что примерно с 90 дня банк стал лучше справляться с несостоятельными клиентами. Попробуем из этого предположения создать новый бинарный признак."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['default_peak'] = (df.days_between_firstdate > 90).astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим распределение дефолта по регионам"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df[(df.Train==1)]\nsns.countplot(x=\"region_rating\", hue=\"default\", data=train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Бинарные признаки 'sex', 'car', 'car_type', 'good_work', 'foreign_passport'"},{"metadata":{},"cell_type":"markdown","source":"Данные признаки содержат всего по два значения, поэтому в будущем просто закодируем их через LabelEncoder"},{"metadata":{},"cell_type":"markdown","source":"## Посмотрим на корреляцию признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_df[num_cols+['default']].corr(), annot=True, fmt='.2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим особой корреляции между признакими нету, поэтому оставляем все в работе."},{"metadata":{},"cell_type":"markdown","source":"## Значимость переменных по ANOVA F-Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_fclassif(train_df, num_cols, 'default')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из f-теста видим, что основной акцент при работе над новыми признаками следует уделить score_bki, decline_app_cnt и bki_request_cnt."},{"metadata":{},"cell_type":"markdown","source":"## Значимость категориальных переменных"},{"metadata":{"trusted":true},"cell_type":"code","source":"labelEncoder = LabelEncoder()\n\n# Закодируем бинарные признаки\nfor column in bin_cols:\n    df[column] = labelEncoder.fit_transform(df[column])\n    \n# Закодируем признак education, но сперва заполним пропуски самым частым значением\ndf.education = df.education.fillna('SCH')\ndf.education = labelEncoder.fit_transform(df.education)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_mutual_info_classif(df[df.Train==1], bin_cols+cat_cols, 'default')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что сильная взаимная информация между таргетом и признаками sna, first_time, region_rating и home_address. Это знание поможет нам в feature engineering."},{"metadata":{},"cell_type":"markdown","source":"## Посмотрим на выбросы"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df[df.Train==1]\nplot_outliers(train_df[num_cols[1:6]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что присутствует достаточное количество выбросов в наших признаках. Попробуем обучить модель с ними, а дальше будет видно."},{"metadata":{},"cell_type":"markdown","source":"# 5. Обработка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Категориальные признаки\ndf = pd.get_dummies(df, columns=cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выполним нормализацию данных\nrs = RobustScaler() # Используем робастный нормализатор, т.к. он устойчив к выбросам\n\ndf[num_cols] = rs.fit_transform(df[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим еще раз на наши данные\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем лишние признаки\ndf.drop(['app_date'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Построение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Готовим данные для обучения модели\ntrain_data = df[df.Train == 1].drop(['Train'], axis=1)\ntest_data = df[df.Train == 0].drop(['Train'], axis=1)\n\ny = train_data.default.values\nX = train_data.drop(['default'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем нашу выборку на обучающую и тестовую\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Выполняем обучение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=RANDOM_SEED, max_iter=500)\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\ny_pred_prob = model.predict_proba(X_test)[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Проводим оценку модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_metrics(y_test, y_pred, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ROC кривая"},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_plot(y_test, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Матрица ошибок"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model, X_test, y_test, values_format='d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим наша модель очень плохо предсказывает дефолтных клиентов из-за сильной несбалансированности нашей выборки. Хотя ROC-AUC показывает достаточно высокое значение, наша  модель выдает очень большую ошибку второго рода. С этим нужно что-то делать. По f1_score можно заметить, что модель несправляется с задачей. Посмотрим еще на одну метрику PRC-AUC, которая поможет оценить алгоритм на несбалансированных данных."},{"metadata":{},"cell_type":"markdown","source":"## Precision-Recall кривая"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prc_auc(model, X_test, y_test, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Кросс-валидация"},{"metadata":{"trusted":true},"cell_type":"code","source":"validate = cross_validate(model, X_test, y_test, cv=10, scoring='roc_auc', return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crossval_score(validate, 'ROC-AUC')\nprint(np.mean(validate['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полученная модель показывает плохие результаты, хотя метрика ROC-AUC имеет достаточно высокое значение (0.745).\nПо матрице ошибок видно,что мы предсказали всего **43** дефолтных клиента из **1784**, что принесет банку убытки, потому что наша модель будет одобрять кредиты клиентам, которые не смогут их вернуть.\nПо PR-AUC видно, что качество нашей модели достаточно низкое.\n\nКак видим, при кросс-валидаций на 10 фолдах ROC-AUC достаточно стабилен. Имеется небольшой провал на обучающей выборке. Далее попробуем подобрать параметры модели и посмотреть на результат."},{"metadata":{},"cell_type":"markdown","source":"## Поиск оптимальных параметров модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Используем GridSearchCV для поиска оптимальных параметров модели\n# model = LogisticRegression(random_state=RANDOM_SEED)\n\n# iter_ = 500\n# epsilon_stop = 1e-3\n# C = np.arange(0, 1, 10)\n\n# param_grid = [\n#     {'penalty': ['l1'], \n#      'solver': ['liblinear', 'lbfgs'], \n#      'class_weight':['none', 'balanced'], \n#      'multi_class': ['auto','ovr'], \n#      'max_iter':[iter_],\n#      'C': C,\n#      'tol':[epsilon_stop]},\n#     {'penalty': ['l2'], \n#      'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n#      'class_weight':['none', 'balanced'], \n#      'multi_class': ['auto','ovr'], \n#      'max_iter':[iter_],\n#      'C': C,\n#      'tol':[epsilon_stop]},\n#     {'penalty': ['none'], \n#      'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n#      'class_weight':['none', 'balanced'], \n#      'multi_class': ['auto','ovr'], \n#      'max_iter':[iter_],\n#      'tol':[epsilon_stop]},\n# ]\n# gridsearch = GridSearchCV(model, param_grid, scoring='f1', n_jobs=-1, cv=5)\n# gridsearch.fit(X_train, y_train)\n# model = gridsearch.best_estimator_\n# # Выведем параметры\n# best_parameters = model.get_params()\n# for param_name in sorted(best_parameters.keys()):\n#         print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n# # Выведем метрики\n# preds = model.predict(X_test)\n# print('Accuracy: %.4f' % accuracy_score(y_test, preds))\n# print('Precision: %.4f' % precision_score(y_test, preds))\n# print('Recall: %.4f' % recall_score(y_test, preds))\n# print('F1: %.4f' % f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На подобранных параметрах непохо подросла метрика f1_score. Попробуем обучить модель с новыми параметрами."},{"metadata":{},"cell_type":"markdown","source":"## Вторая модель с подобранными параметрами"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = prepare_data(df)\n\nmodel = LogisticRegression(random_state=RANDOM_SEED, \n                           C=1, \n                           class_weight= 'balanced', \n                           dual= False, \n                           fit_intercept= True, \n                           intercept_scaling= 1, \n                           l1_ratio= None, \n                           multi_class= 'auto', \n                           n_jobs= None, \n                           penalty= 'none', \n                           solver = 'sag',\n                           max_iter = 500,\n                           verbose= 0, \n                           warm_start= False)\n\nmodel.fit(X_train, y_train)\n\ny_pred_prob = model.predict_proba(X_test)[:,1]\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Оценим качество второй модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_metrics(y_test, y_pred, y_pred_prob)\nvalidate = cross_validate(model, X_test, y_test, cv=10, scoring='roc_auc', return_train_score=True)\nprint(np.mean(validate['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на матрицу ошибок."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model, X_test, y_test, values_format='d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_plot(y_test, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prc_auc(model, X_test, y_test, y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Попробуем разные Pipeline"},{"metadata":{},"cell_type":"markdown","source":"# preprocessing->Different classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV\nfrom sklearn.linear_model import SGDClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\ndf = load_data(preprocess=False, drop_outliers=False, outliers_column='income', log_numerical=True)\n\n# Разобьем данные\nX_train, X_test, y_train, y_test = prepare_data(df)\n\n# Модель 1\nlr0 = LogisticRegression(random_state=RANDOM_SEED, \n                           C=1, \n                           class_weight= 'balanced', \n                           dual= False, \n                           fit_intercept= True, \n                           intercept_scaling= 1, \n                           l1_ratio= None, \n                           multi_class= 'auto', \n                           n_jobs= None, \n                           penalty= 'none', \n                           solver = 'sag',\n                           max_iter = 500,\n                           verbose= 0, \n                           warm_start= False)\n\n# Модель 2\nlr1 = LogisticRegression(random_state=RANDOM_SEED, \n                           C=1.5, \n                           class_weight= 'balanced', \n                           dual= False, \n                           fit_intercept= True, \n                           intercept_scaling= 1, \n                           l1_ratio= None, \n                           multi_class= 'auto', \n                           n_jobs= None, \n                           penalty= 'l2', \n                           solver = 'lbfgs',\n                           max_iter = 500,\n                           verbose= 0, \n                           warm_start= False)\n\n# Предобработка данных\npreprocessing = prepare_data_pipeline(scaler='robust', polynomial_features=False, polynomial_n=3)\n\n# # Воспользуемся RandomizedSearchCV для более быстрого подбора параметров модели\n# # Количество деревьев\n# n_estimators = np.arange(200, 1000, 200)\n# # Количество фич\n# max_features = ['auto', 'sqrt']\n# # Глубина дерева\n# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n# max_depth.append(None)\n# # Минимальное количество сэмплов для сплита\n# min_samples_split = [2, 5, 10]\n# # Минимальное количество сэмплов в листе\n# min_samples_leaf = [1, 2, 4]\n# # Метод выбора сэмплов\n# bootstrap = [True, False]\n\n# # Рандомная сетка подбора параметров для деревьев\n# random_grid_tree = {\n#                        'max_features': max_features,\n#                        'max_depth': max_depth,\n#                        'min_samples_split': min_samples_split,\n#                        'min_samples_leaf': min_samples_leaf,\n#                        'bootstrap': bootstrap}\n\n# parameters = { 'tree': {\n#                             'decisiontreeclassifier__max_features': max_features,\n#                             'decisiontreeclassifier__min_samples_split': min_samples_split,\n#                             'decisiontreeclassifier__min_samples_leaf': min_samples_leaf,\n#                             'decisiontreeclassifier__max_depth': max_depth,\n#                         },\n#                 'forest': {\n#                             'randomforestclassifier__max_features': max_features,\n#                             'randomforestclassifier__min_samples_split': min_samples_split,\n#                             'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n#                             'randomforestclassifier__bootstrap': bootstrap,\n#                             'randomforestclassifier__max_depth': max_depth,\n#                             #'randomforestclassifier__n_estimators': n_estimators,\n#                         },\n#                 'gbc':  {\n#                             'gradientboostingclassifier__max_features': max_features,\n#                             'gradientboostingclassifier__min_samples_split': min_samples_split,\n#                             'gradientboostingclassifier__min_samples_leaf': min_samples_leaf,\n#                             'gradientboostingclassifier__max_depth': max_depth,\n#                             #'gradientboostingclassifier__n_estimators': n_estimators,\n#                         },\n#                  'xgb': {\n#                             'xgbclassifier__min_child_weight': [1, 5, 10],\n#                             'xgbclassifier__gamma': [0.5, 1, 1.5, 2, 5],\n#                             'xgbclassifier__subsample': [0.6, 0.8, 1.0],\n#                             'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],\n#                             'xgbclassifier__max_depth': [3, 4, 5, 10]\n#                  },\n#                  'ada': {\n#                              'adaboostclassifier__n_estimators':[500, 1000, 1500, 2000], \n#                              'adaboostclassifier__learning_rate':[0.05, 0.1, 0.15, 0.2]\n#                  }\n# }\n\n\n# # Подбор параметров для Tree-based алгоритмов\n# tree_classifiers = [\n#     #{ 'classifier': DecisionTreeClassifier(), 'type': 'tree'}, { 'classifier': RandomForestClassifier(), 'type': 'forest' },\n#     #{ 'classifier': GradientBoostingClassifier(), 'type': 'gbc'},\n#     #{ 'classifier': XGBClassifier(), 'type': 'xgb'},\n#     { 'classifier': AdaBoostClassifier(), 'type': 'ada'},\n# ]\n\n# best_params = []\n\n# for tree in tree_classifiers:\n#     pipe = make_pipeline(preprocessing, tree['classifier'])\n#     rcv = RandomizedSearchCV(pipe, parameters[tree['type']], cv=5, scoring='roc_auc', verbose=True, n_jobs=-1)\n    \n#     print(f'Fitting: {tree}')\n#     rcv.fit(X_train, y_train)\n    \n#     best_params.append({'clf': tree['classifier'], 'best_params': rcv.best_params_, 'best_score': rcv.best_score_})\n#     print(best_params)\n\n# print(f'Best params: {best_params}')\n\n# Переберем разные классификаторы и посмотрим на результат\nclassifiers = [\n    lr0,\n    lr1,\n    SGDClassifier(loss='log'),\n    #KNeighborsClassifier(), - медленная работа и плохой результат\n    DecisionTreeClassifier(min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=10),\n    RandomForestClassifier(n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features='auto', max_depth=10, bootstrap=True),\n    AdaBoostClassifier(n_estimators=100),\n    GradientBoostingClassifier(n_estimators=100),\n    XGBClassifier(verbose=False, objective='reg:logistic', n_estimators=100, subsample=1.0, min_child_weight=1, max_depth=4, gamma=5, colsample_bytree=1.0),\n    LGBMClassifier(),\n    CatBoostClassifier(verbose=False),\n    ]\n\nbest_score = 0\nbest_model = 0\nbest_estimator = []\n\n# Проводим поиск лучшего классификатора\nfor classifier in classifiers:\n    pipe = make_pipeline(preprocessing, classifier)\n\n    print('\\n')\n    print(f'Fitting {classifier}...')\n    pipe.fit(X_train, y_train)\n    print(f'Predicting...')\n    y_pred = pipe.predict(X_test)\n    proba = pipe.predict_proba(X_test)[:, 1]\n    \n    score = roc_auc_score(y_test, proba)\n    print(f'ROC-AUC score is: {score}')\n    \n    if score > best_score:\n        best_score = score\n        best_model = classifier\n        best_estimator.append([best_score, best_model, pipe])\n\nprint(f'Best model is: {best_model} with score: {best_score}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pipe = make_pipeline(preprocessing, lr1)\nvalidate = cross_validate(val_pipe, X_test, y_test, cv=10, scoring='roc_auc', return_train_score=True)\nprint(np.mean(validate['test_score']))\nval_pipe.fit(X_train, y_train)\nplot_confusion_matrix(val_pipe, X_test, y_test, values_format='d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_top_abs_correlations(df.select_dtypes(include=['float64', 'int64']), 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из всех классификаторов лучший результат по метрике roc_auc показывает наша LogisticRegression. Ближе всех по результатам приближаются AdaBoostClassifier и GradientBoostingClassifier. Можно дополнительно попробовать беггинг логистической регрессии раз она показывает лучшие результаты.\n\nПодбор параметров показал, что лучший результат получается, когда в пайплайн добавляем метод главных компонент с количеством признаков 25, но Kaggle говорит нам о другом и результат при использовании PCA падает :("},{"metadata":{},"cell_type":"markdown","source":"# Бэггинг логистической регрессии"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\ndf = load_data(preprocess=False, drop_outliers=False, outliers_column='income')\n\n# Разобьем данные\nX_train, X_test, y_train, y_test = prepare_data(df)\n\n# Посчитаем веса классов\ny0 = len(y_train[y_train == 1])\ny1 = len(y_train[y_train == 0])\n\nw0 = y1/y0\nw1 = 1\n\nsample_weights = np.zeros(len(y_train))\nsample_weights[y_train == 0] = w0\nsample_weights[y_train == 1] = w1\n\nlr = LogisticRegression(random_state=RANDOM_SEED, \n                           C=1.5, \n                           class_weight= 'balanced', \n                           dual= False, \n                           fit_intercept= True, \n                           intercept_scaling= 1, \n                           l1_ratio= None, \n                           multi_class= 'auto', \n                           n_jobs= None, \n                           penalty= 'l2', \n                           solver = 'lbfgs',\n                           max_iter = 500,\n                           verbose= 0, \n                           warm_start= False)\n\n# Предобработка данных\npreprocessing = prepare_data_pipeline()\n\n# Модель\nmodel = BaggingClassifier(lr, \n                      n_estimators=5, \n                      bootstrap = True, random_state = RANDOM_SEED)\n\npipe = make_pipeline(preprocessing, model)\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nproba = pipe.predict_proba(X_test)[:, 1]\n    \nscore = roc_auc_score(y_test, proba)\n\nprint(f'Model score: {score}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pipe = make_pipeline(preprocessing, model)\nvalidate = cross_validate(val_pipe, X_test, y_test, cv=10, scoring='roc_auc', return_train_score=True)\nprint(np.mean(validate['test_score']))\nval_pipe.fit(X_train, y_train)\nplot_confusion_matrix(val_pipe, X_test, y_test, values_format='d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Чуда не произошло - ансамбль логистических регрессий результат не улучшил."},{"metadata":{},"cell_type":"markdown","source":"# Стэкинг моделей\n\nПопробуем объединить в стэк самые популярные алгоритмы классификации."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Загрузим данные\ndf = load_data(preprocess=False, drop_outliers=False, outliers_column='income')\n\n# Разобьем данные\nX_train, X_test, y_train, y_test = prepare_data(df)\n\n# Определяем базовые модели в стэк\nbase_models = [\n                ('bm1', XGBClassifier(objective='reg:logistic', n_estimators=100, subsample=1.0, min_child_weight=1, max_depth=4, gamma=5, colsample_bytree=1.0)),\n                ('bm2', LGBMClassifier()),\n                ('bm3', RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini')),\n                ('bm4', ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'))\n]\n\n# Решающая модель\nblending_model = LogisticRegression(random_state=RANDOM_SEED, \n                                       C=1.5, \n                                       class_weight= 'balanced', \n                                       dual= False, \n                                       fit_intercept= True, \n                                       intercept_scaling= 1, \n                                       l1_ratio= None, \n                                       multi_class= 'auto', \n                                       n_jobs= None, \n                                       penalty= 'l2', \n                                       solver = 'lbfgs',\n                                       max_iter = 500,\n                                       verbose= 0, \n                                       warm_start= False)\n\n# Стэк\nstack_model = StackingClassifier(estimators=base_models, final_estimator=blending_model)\n\n# Предобработка данных\npreprocessing = prepare_data_pipeline()\n\n# Наш пайп\nfinal_pipe = make_pipeline(preprocessing, stack_model)\n\n# Обучаем стэк\nfinal_pipe.fit(X_train, y_train)\ny_pred = final_pipe.predict(X_test)\nproba = final_pipe.predict_proba(X_test)[:, 1]\n    \nscore = roc_auc_score(y_test, proba)\n\nprint(f'Model score: {score}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Загрузим данные\ndf = load_data(preprocess=False, drop_outliers=False, outliers_column='income')\n\n# Разобьем данные\nX_train, X_test, y_train, y_test = prepare_data(df)\n\n# Предобработка данных\npreprocessing = prepare_data_pipeline(scaler='robust')\n\n# Классификатор\nclf = LogisticRegression(random_state=RANDOM_SEED, \n                                       C=1.5, \n                                       class_weight= 'balanced', \n                                       dual= False, \n                                       fit_intercept= True, \n                                       intercept_scaling= 1, \n                                       l1_ratio= None, \n                                       multi_class= 'auto', \n                                       n_jobs= None, \n                                       penalty= 'l2', \n                                       solver = 'lbfgs',\n                                       max_iter = 1000,\n                                       verbose= 0, \n                                       warm_start= False)\n\n#num_features = X_test.select_dtypes(include='float64')\nnum_features = ['decline_app_cnt', 'bki_request_cnt', 'score_bki', 'income']\n\npipeline_features = [['mul', 'std']]\n\n# results = []\n# # Pipeline\n# for pipeline_feature in pipeline_features:\n#     pipeline = make_pipeline(FeatureGenerator(feature_list=num_features, primitives=pipeline_feature), preprocessing, RobustScaler(), clf)\n#     validate = cross_validate(pipeline, X_train, y_train, cv=3, scoring='roc_auc', return_train_score=True)\n\n#     results.append({'score': np.mean(validate['test_score']), 'feature_param': pipeline_feature})\n\n# print(results)\npipeline = make_pipeline(FeatureGenerator(feature_list=num_features, primitives=pipeline_feature), preprocessing, RobustScaler(), clf)\nvalidate = cross_validate(pipeline, X_train, y_train, cv=3, scoring='roc_auc', return_train_score=True)\nprint(np.mean(validate['test_score']))\n","execution_count":155,"outputs":[{"output_type":"stream","text":"0.7326479068274905\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"- [{'score': 0.7327340883552927, 'feature_param': ['mul', 'mean']}]\n- [{'score': 0.7327220181577214, 'feature_param': ['mul']}]\n- [{'score': 0.732755392108973, 'feature_param': ['mul', 'std']}]\n- [{'score': 0.7327734423515534, 'feature_param': ['mul', 'std', 'sum']}]\n- [{'score': 0.732788267061245, 'feature_param': ['mul', 'std', 'sub']}]\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = load_data(preprocess=False, drop_outliers=False, outliers_column='income', log_numerical=True)\n\ntrain_data = df.query('Train == 1').drop(['Train'], axis=1)\ntest_data = df.query('Train == 0').drop(['Train'], axis=1)\n\ndf_test = pd.read_csv(PATH_to_file+'test.csv')","execution_count":146,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалим выбросы по income\n#train_data = remove_outliers_iqr_column(train_data, 'income')\n\nX_train=train_data.drop(['default'], axis=1)\ny_train = train_data.default.values\nX_test = test_data.drop(['default'], axis=1)","execution_count":147,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Наша лучшая модель\nlr = LogisticRegression(random_state=RANDOM_SEED, \n                           C=1.5, \n                           class_weight= 'balanced', \n                           dual= False, \n                           fit_intercept= True, \n                           intercept_scaling= 1, \n                           l1_ratio= None, \n                           multi_class= 'auto', \n                           n_jobs= None, \n                           penalty= 'l2', \n                           solver = 'lbfgs',\n                           max_iter = 500,\n                           verbose= 0, \n                           warm_start= False)\n\n# Предобработка данных\npreprocessing = prepare_data_pipeline(scaler='robust')\n\n# model = BaggingClassifier(lr, \n#                       n_estimators=15, \n#                       bootstrap = True, random_state = RANDOM_SEED)\n\n# best_pipe = make_pipeline(preprocessing, model)\n# best_pipe.fit(X_train, y_train)\n# y_pred_prob = best_pipe.predict_proba(X_test)[:,1]\n# y_pred = best_pipe.predict(X_test)\n\n\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\nproba = pipeline.predict_proba(X_test)[:, 1]","execution_count":148,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(test_data.client_id)\nsubmit['default']=proba\nsubmit.to_csv('submission.csv', index=False)\n","execution_count":149,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Вывод:** За время хакатона удалось добиться результата метрики: **0.73766**\nДанный датасет показал лучшие результаты на логистической регрессии с подобранными GridSearchCV гиперпараметрами. Что не успел: Проверить автоматический фичаинжениринг через featuretools и найти скрытые инсайты.\n\n**Дополнительно:** После хакатона написал класс генерации признаков FeatureGenerator, который методом подбора примитивов (лучшим было перемножение признаков)показал лучший результат: **0.73799**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}