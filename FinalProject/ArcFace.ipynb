{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e18ada9",
   "metadata": {},
   "source": [
    "# Обучение сети для извлечения дескрипторов лица\n",
    "## Реализация InsightFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a89a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfec75c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  GeForce GTX 1060 6GB, compute capability 6.1\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719fdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим наш датасет для обучения\n",
    "# Данные в реализации Insightface хранятся в формате MXNet Record из которых необходимо извлечь картинки для обучения\n",
    "def MXnet_record_to_folder(dataset_dir, save_dir=None):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import mxnet as mx\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    if save_dir == None:\n",
    "        save_dir = (dataset_dir[:-1] if dataset_dir.endswith(\"/\") else dataset_dir) + \"_112x112_folders\"\n",
    "    idx_path = os.path.join(dataset_dir, \"train.idx\")\n",
    "    bin_path = os.path.join(dataset_dir, \"train.rec\")\n",
    "\n",
    "    print(\"save_dir = %s, idx_path = %s, bin_path = %s\" % (save_dir, idx_path, bin_path))\n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"%s already exists.\" % save_dir)\n",
    "        return\n",
    "\n",
    "    imgrec = mx.recordio.MXIndexedRecordIO(idx_path, bin_path, \"r\")\n",
    "    rec_header, _ = mx.recordio.unpack(imgrec.read_idx(0))\n",
    "\n",
    "    for ii in tqdm(range(1, int(rec_header.label[0]))):\n",
    "        img_info = imgrec.read_idx(ii)\n",
    "        header, img = mx.recordio.unpack(img_info)\n",
    "        # img_idx = str(int(np.sum(header.label)))\n",
    "        img_idx = str(int(header.label if isinstance(header.label, float) else header.label[0]))\n",
    "        img_save_dir = os.path.join(save_dir, img_idx)\n",
    "        if not os.path.exists(img_save_dir):\n",
    "            os.makedirs(img_save_dir)\n",
    "        with open(os.path.join(img_save_dir, str(ii) + \".jpg\"), \"wb\") as ff:\n",
    "            ff.write(img)\n",
    "\n",
    "\n",
    "def MXnet_bin_files_to_tf(test_bins, limit=0):\n",
    "    import io\n",
    "    import pickle\n",
    "    import tensorflow as tf\n",
    "    from skimage.io import imread\n",
    "\n",
    "    print(\"test_bins =\", test_bins)\n",
    "    for test_bin_file in test_bins:\n",
    "        with open(test_bin_file, \"rb\") as ff:\n",
    "            bins, issame_list = pickle.load(ff, encoding=\"bytes\")\n",
    "\n",
    "        bb = [bytes(ii) for ii in bins[: limit * 2] + bins[-limit * 2 :]]\n",
    "        print(\"Saving to %s\" % test_bin_file)\n",
    "        with open(test_bin_file, \"wb\") as ff:\n",
    "            pickle.dump([bb, issame_list[:limit] + issame_list[-limit:]], ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa0a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir = /app/data/ms1m-retinaface-t1_112x112_folders, idx_path = /app/data/ms1m-retinaface-t1/train.idx, bin_path = /app/data/ms1m-retinaface-t1/train.rec\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../3rdparty/dmlc-core/src/io/local_filesys.cc\", line 209\nLocalFileSystem: Check failed: allow_null: :Open \"/app/data/ms1m-retinaface-t1/train.rec\": No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-417a33ee0379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Извлекаем картинки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mMXnet_record_to_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Конвертим bin файлы для работы с TF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2b89cf7528b5>\u001b[0m in \u001b[0;36mMXnet_record_to_folder\u001b[0;34m(dataset_dir, save_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimgrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecordio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXIndexedRecordIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mrec_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecordio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, idx_path, uri, flag, key_type)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMXIndexedRecordIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, flag)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMXIndexedRecordIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXRecordIOReaderCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../3rdparty/dmlc-core/src/io/local_filesys.cc\", line 209\nLocalFileSystem: Check failed: allow_null: :Open \"/app/data/ms1m-retinaface-t1/train.rec\": No such file or directory"
     ]
    }
   ],
   "source": [
    "# Пути к датасету\n",
    "DATASET = 'ms1m-retinaface-t1'\n",
    "DATASET_DIR = f'/app/data/{DATASET}'\n",
    "\n",
    "EVAL_BINS = [DATASET_DIR+'/lfw.bin', DATASET_DIR+'/cfp_fp.bin', DATASET_DIR+'/agedb_30.bin']\n",
    "\n",
    "# Извлекаем картинки\n",
    "MXnet_record_to_folder(DATASET_DIR)\n",
    "\n",
    "# Конвертим bin файлы для работы с TF\n",
    "MXnet_bin_files_to_tf(EVAL_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f88aa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load model from h5 file: checkpoints/keras_resnet100_emore_add5epoch_basic_agedb_30_epoch_3_0.967333.h5...\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      ">>>> L2 regularizer value from basic_model: 0\n",
      ">>>> Init type by loss function name...\n",
      ">>>> Train arcface...\n",
      ">>>> Init softmax dataset...\n",
      ">>>> reloaded from dataset backup: ms1m-retinaface-t1_112x112_folders_shuffle.npz\n",
      ">>>> Image length: 5179510, Image class length: 5179510, classes: 93431\n",
      ">>>> Use specified optimizer: <tensorflow_addons.optimizers.weight_decay_optimizers.SGDW object at 0x7fa22c147fd0>\n",
      ">>>> Insert weight decay callback...\n",
      ">>>> Add arcface layer, loss_top_k=1...\n",
      ">>>> loss_weights: {'arcface': 1}\n",
      "Epoch 1/5\n",
      "\n",
      "Learning rate for iter 1 is 0.10000000149011612\n",
      "Weight decay is 0.0005000000237487257\n",
      "  246/51795 [..............................] - ETA: 5:46:18 - loss: nan - accuracy: 0.0016    Batch 245: Invalid loss, terminating training\n",
      "51795/51795 [==============================] - 131s 2ms/step - loss: nan - accuracy: 0.0016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating lfw: 100%|██████████| 120/120 [00:33<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN in embs, not a good one\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating cfp_fp: 100%|██████████| 140/140 [00:38<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN in embs, not a good one\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating agedb_30: 100%|██████████| 120/120 [00:33<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN in embs, not a good one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to checkpoints/keras_resnet100_emore_add5epoch.h5\n",
      "\n",
      "Continue? ([Y]/n): \n",
      ">>>> Train arcface DONE!!! epochs = [0], model.stop_training = True\n",
      ">>>> My history:\n",
      "{\n",
      "  'lr': [0.09903939813375473, 0.09619443863630295, 0.09157442301511765, 0.0853569433093071, 0.09999997913837433],\n",
      "  'loss': [15.516167640686035, 8.281216621398926, 7.494349002838135, 7.060657024383545, nan],\n",
      "  'accuracy': [0.6002210378646851, 0.9365062117576599, 0.9491091966629028, 0.9548008441925049, 0.00162601622287184],\n",
      "  'lfw': [0.996, 0.9956666666666667, 0.9968333333333333, 0.997, 0.0],\n",
      "  'lfw_thresh': [0.3250987231731415, 0.33404529094696045, 0.3266749680042267, 0.32773804664611816, 0.0],\n",
      "  'cfp_fp': [0.9505714285714286, 0.9644285714285714, 0.9687142857142857, 0.9708571428571429, 0.0],\n",
      "  'cfp_fp_thresh': [0.21803595125675201, 0.22251766920089722, 0.21157196164131165, 0.22387471795082092, 0.0],\n",
      "  'agedb_30': [0.9443333333333334, 0.9616666666666667, 0.9673333333333334, 0.9665, 0.0],\n",
      "  'agedb_30_thresh': [0.25916093587875366, 0.29036784172058105, 0.2784630358219147, 0.26903432607650757, 0.0],\n",
      "}\n",
      "\n",
      ">>>> But it's an early stop, break...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import losses, train, models\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# ResNet100 MXNet backbone + DepthWise Conv\n",
    "basic_model = models.buildin_models(\"r100\", dropout=0, emb_shape=512, output_layer=\"GDC\")\n",
    "\n",
    "data_path = f'/app/data/{DATASET}_112x112_folders'\n",
    "\n",
    "tt = train.Train(data_path, save_path='keras_resnet100_emore_add5epoch.h5', eval_paths=EVAL_BINS,\n",
    "                basic_model=None, model='checkpoints/keras_resnet100_emore_add5epoch_basic_agedb_30_epoch_3_0.967333.h5', batch_size=100, random_status=0,\n",
    "                lr_base=0.1, lr_decay=0.5, lr_decay_steps=16, lr_min=1e-5)\n",
    "\n",
    "optimizer = tfa.optimizers.SGDW(learning_rate=0.01, momentum=0.9, weight_decay=5e-5)\n",
    "\n",
    "sch = [\n",
    "  #{\"loss\": losses.ArcfaceLoss(scale=16), \"epoch\": 5, \"optimizer\": optimizer},\n",
    "  #{\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 5, \"optimizer\": optimizer},\n",
    "  {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 5, \"optimizer\": optimizer},\n",
    "]\n",
    "\n",
    "tt.train(sch, 0)\n",
    "#tt.train_single_scheduler(loss=losses.ArcfaceLoss(scale=64), epoch=5, optimizer=optimizer, initial_epoch=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ad0df",
   "metadata": {},
   "source": [
    "# Проверим точность на LFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63bfbcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating lfw: 100%|██████████| 94/94 [02:26<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> lfw evaluation max accuracy: 0.996333, thresh: 0.350268, previous max accuracy: 0.000000\n",
      ">>>> Improved = 0.996333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import evals\n",
    "EVALSET_DIR = f'/app/data/faces_emore'\n",
    "basic_model = keras.models.load_model('checkpoints/keras_resnet100_emore_add5epoch_basic_agedb_30_epoch_3_0.967333.h5', compile=False)\n",
    "ee = evals.eval_callback(basic_model, f'{EVALSET_DIR}/lfw.bin')\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f04b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
