{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 22:31:42.851028: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-11-02 22:31:42.851059: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (GrPC): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.face import FaceDetector\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_16749/3146209340.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 22:31:42.878353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "\n",
    "#tf.config.set_visible_devices([], 'GPU')\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(), 'models', 'glint360k_cosface_r100_fp16_0.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = load_model(model_path, compile=False)\n",
    "face_detector = FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "def face_align_landmarks_sk(img, landmarks, image_size=(112, 112), method=\"similar\"):\n",
    "    tform = transform.AffineTransform() if method == \"affine\" else transform.SimilarityTransform()\n",
    "    src = np.array([[38.2946, 51.6963], [73.5318, 51.5014], [56.0252, 71.7366], [41.5493, 92.3655], [70.729904, 92.2041]], dtype=np.float32)\n",
    "    ret = []\n",
    "    for landmark in landmarks:\n",
    "        tform.estimate(landmark, src)\n",
    "        aligned_img = transform.warp(img, tform.inverse, output_shape=image_size)\n",
    "        ret.append(aligned_img)\n",
    "\n",
    "    return (np.array(ret) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def do_detect_in_image(image, det, image_format=\"BGR\"):\n",
    "    imm_BGR = image if image_format == \"BGR\" else image[:, :, ::-1]\n",
    "    imm_RGB = image[:, :, ::-1] if image_format == \"BGR\" else image\n",
    "    bboxes, pps = det.detect(imm_BGR)\n",
    "    nimgs = face_align_landmarks_sk(imm_RGB, pps)\n",
    "    \n",
    "    return bboxes, nimgs\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    _, img = do_detect_in_image(img, face_detector, image_format=\"RGB\")\n",
    "    img = ((img - 127.5) * 0.0078125)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def embedding_images(imgs, batch_size=32):\n",
    "    steps = int(np.ceil(len(imgs) / batch_size))\n",
    "    embeddings = [face_model(imgs[ii * batch_size : (ii + 1) * batch_size]) for ii in range(steps)]\n",
    "    embeddings = normalize(np.concatenate(embeddings, axis=0))\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "image_classes = ['jolie', 'clark', 'brad']\n",
    "img1 = imread('jolie.jpg')\n",
    "img2 = imread('clark.jpeg')\n",
    "img3 = imread('brad2.jpg')\n",
    "\n",
    "imgs = [prepare_image(img) for img in [img1, img2, img3]]\n",
    "imgs = np.concatenate(imgs, axis=0)\n",
    "\n",
    "embeddings = embedding_images(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обнаружено лицо: ['jolie', 'brad'] [0.5764251, 0.048944745]\n"
     ]
    }
   ],
   "source": [
    "from skimage import img_as_ubyte\n",
    "\n",
    "face_threshold = 0.4\n",
    "\n",
    "test_img = imread('jolie7.jpeg')\n",
    "test_img = prepare_image(test_img)\n",
    "emb_test = embedding_images([test_img])\n",
    "\n",
    "dists = np.dot(embeddings, emb_test.T).T\n",
    "rec_idx = dists.argmax(-1)\n",
    "\n",
    "rec_dist = [dists[id, ii] for id, ii in enumerate(rec_idx)]\n",
    "rec_class = [image_classes[ii] for ii in rec_idx]\n",
    "\n",
    "\n",
    "print(f'Обнаружено лицо: {rec_class} {rec_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
