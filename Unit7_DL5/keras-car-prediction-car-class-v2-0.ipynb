{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["> Это пример решения задачи с использованием Keras. Вы можете использовать этот кернер для дальнейших исследований и экспериментов.\n","# Классификация изображений\n","\n","### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \n","По ходу решения мы будем давать вам рекомендации, которые помогут улучшить качество модели. \n","\n","\n","Удачи и Поехали!"],"metadata":{}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q efficientnet"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/mjkvaak/ImageDataAugmentor"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import zipfile\n","import csv\n","import sys\n","import os\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.callbacks import Callback\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.applications.xception import Xception\n","import tensorflow.keras.layers as L\n","\n","import efficientnet.tfkeras as efn\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","import PIL\n","from PIL import ImageOps, ImageFilter\n","#увеличим дефолтный размер графиков\n","from pylab import rcParams\n","rcParams['figure.figsize'] = 10, 5\n","#графики в svg выглядят более четкими\n","%config InlineBackend.figure_format = 'svg' \n","%matplotlib inline\n","\n","print(os.listdir(\"../input\"))\n","print('Python       :', sys.version.split('\\n')[0])\n","print('Numpy        :', np.__version__)\n","print('Tensorflow   :', tf.__version__)\n","print('Keras        :', tf.keras.__version__)"],"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Вспомагательные функции\n","def plot_history(history):\n","    plt.figure(figsize=(10,5))\n","    #plt.style.use('dark_background')\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs = range(len(acc))\n","\n","    plt.plot(epochs, acc, 'b', label='Training acc')\n","    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.legend()\n","\n","    #plt.figure()\n","    plt.figure(figsize=(10,5))\n","    #plt.style.use('dark_background')\n","    plt.plot(epochs, loss, 'b', label='Training loss')\n","    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.legend()\n","\n","    plt.show()\n","    \n","\n","# Fastai plot_top_losses style\n","def plot_top_losses(actual, pred, loss, k=9, figsize=(10,10)):\n","  loss_values = loss(actual,pred).numpy()\n","  top_k = loss_values.argsort()[-k:][::-1]\n","  cols = math.ceil(math.sqrt(k))\n","  rows = math.ceil(k/cols)\n","  fig,axes = plt.subplots(rows, cols, figsize=figsize)\n","  fig.suptitle('Prediction/Actual/Loss/Prediction_Probability', weight='bold', size=14)\n","  i =0\n","  for index in top_k:\n","    image = test_images[index]\n","    actual = test_labels[index]\n","    loss_value = loss_values[index]\n","    predicted = np.argmax(pred[index])\n","    prob = pred[index][predicted]\n","    title = f'{predicted}/{actual}/{loss_value:.2f}/{prob:.2f}'\n","    ax = axes.flat[i]\n","    i+=1\n","    image = np.squeeze(image,axis=2)\n","    ax.imshow(image)\n","    ax.set_title(title)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Работаем с Tensorflow v2**"],"metadata":{}},{"cell_type":"code","source":["!pip freeze > requirements.txt"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Основные настройки"],"metadata":{}},{"cell_type":"code","source":["# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n","\n","EPOCHS               = 10  # эпох на обучение\n","BATCH_SIZE           = 32 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\n","LR                   = 1e-3\n","VAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n","\n","CLASS_NUM            = 10  # количество классов в нашей задаче\n","IMG_SIZE             = 224 # какого размера подаем изображения в сеть\n","IMG_CHANNELS         = 3   # у RGB 3 канала\n","input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n","\n","DATA_PATH = '../input/'\n","PATH = \"../working/car/\" # рабочая директория"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Устаналиваем конкретное значение random seed для воспроизводимости\n","os.makedirs(PATH,exist_ok=False)\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)  \n","PYTHONHASHSEED = 0"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA / Анализ данных"],"metadata":{}},{"cell_type":"code","source":["train_df = pd.read_csv(DATA_PATH+\"train.csv\")\n","sample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\n","train_df.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.Category.value_counts()\n","# распределение классов достаточно равномерное - это хорошо"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Распаковываем картинки')\n","# Will unzip the files so that you can see them..\n","for data_zip in ['train.zip', 'test.zip']:\n","    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n","        z.extractall(PATH)\n","        \n","print(os.listdir(PATH))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Пример картинок (random sample)')\n","plt.figure(figsize=(12,8))\n","\n","random_image = train_df.sample(n=9)\n","random_image_paths = random_image['Id'].values\n","random_image_cat = random_image['Category'].values\n","\n","for index, path in enumerate(random_image_paths):\n","    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n","    plt.subplot(3,3, index+1)\n","    plt.imshow(im)\n","    plt.title('Class: '+str(random_image_cat[index]))\n","    plt.axis('off')\n","plt.show()"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать."],"metadata":{}},{"cell_type":"code","source":["image = PIL.Image.open(PATH+'/train/0/100380.jpg')\n","imgplot = plt.imshow(image)\n","plt.show()\n","image.size"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Как видим, в датасете все автомобили делятся на марки Автоваза и Вольквагена."],"metadata":{}},{"cell_type":"markdown","source":["# Подготовка данных"],"metadata":{}},{"cell_type":"markdown","source":["### Аугментация данных"],"metadata":{}},{"cell_type":"code","source":["from ImageDataAugmentor.image_data_augmentor import *\n","import albumentations as A"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUGMENTATIONS = A.Compose([\n","    A.OneOf([\n","        A.RandomBrightnessContrast(brightness_limit=0.3, \n","                                                contrast_limit=0.3),\n","        A.RandomBrightnessContrast(brightness_limit=0.1, \n","                                                contrast_limit=0.1)],\n","        p=0.5),\n","    A.GaussianBlur(p=0.05),\n","    A.RandomBrightness(limit=0.2, p=0.5),\n","    A.ShiftScaleRotate(shift_limit=0.0625, \n","                       scale_limit=0.01, \n","                       interpolation=1, \n","                       border_mode=4, \n","                       rotate_limit=10, \n","                       p=.75),\n","    A.HorizontalFlip(p=0.5),\n","    A.HueSaturationValue(p=0.5),\n","    A.RGBShift(p=0.5),\n","    A.FancyPCA(alpha=0.1, \n","               always_apply=False, \n","               p=0.5),\n","    A.Resize(IMG_SIZE, IMG_SIZE)\n","])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Вы помните, что аугментация данных важна, когда мы работаем с небольшим датасетом. Это как раз наш случай.\n","# Чтобы лучше понять работу параметров, попробуйте их изменить. К какому результату это приведет?\n","# Официальная документация: https://keras.io/preprocessing/image/\n","\n","# train_datagen = ImageDataGenerator(\n","#     rescale=1. / 255,\n","#     rotation_range = 5,\n","#     width_shift_range=0.1,\n","#     height_shift_range=0.1,\n","    \n","#     validation_split=VAL_SPLIT, # set validation split\n","#     horizontal_flip=False)\n","\n","train_gen = ImageDataAugmentor(rescale=1./255,\n","                        augment=AUGMENTATIONS, \n","                        seed=RANDOM_SEED,\n","                        validation_split=VAL_SPLIT\n","                       )\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","#Рекомендация Подключите более продвинутые библиотеки аугментации изображений (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, например: https://github.com/mjkvaak/ImageDataAugmentor)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Генерация данных"],"metadata":{}},{"cell_type":"code","source":["# Завернем наши данные в генератор:\n","\n","train_generator = train_gen.flow_from_directory(\n","    PATH+'train/',      # директория где расположены папки с картинками \n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training') # set as training data\n","\n","test_generator = train_gen.flow_from_directory(\n","    PATH+'train/',\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='validation') # set as validation data\n","\n","test_sub_generator = test_datagen.flow_from_dataframe( \n","    dataframe=sample_submission,\n","    directory=PATH+'test_upload/',\n","    x_col=\"Id\",\n","    y_col=None,\n","    shuffle=False,\n","    class_mode=None,\n","    seed=RANDOM_SEED,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,)\n","\n","# Тестовые данные не прогоняем через аугментацию для более точной валидации"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator.show_data(rows=3, cols=5)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Построение модели"],"metadata":{}},{"cell_type":"markdown","source":["### Загружаем предобученную сеть EfficientNet B5:\n","Данная сеть показала более эффективную работы по сравнению с Xception и InceptionV3"],"metadata":{}},{"cell_type":"code","source":["#base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n","base_model = efn.EfficientNetB5(weights='imagenet', include_top=False, input_shape = input_shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model.summary()"],"metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Замораживаем базовую модель для файн тюнинга\n","base_model.trainable = False\n","\n","# Устанавливаем новую \"голову\" (head)\n","model=Sequential()\n","model.add(base_model)\n","model.add(L.GlobalAveragePooling2D(),)\n","model.add(L.Dense(256, activation='relu'))\n","model.add(L.BatchNormalization())\n","model.add(L.Dropout(0.25))\n","model.add(L.Dense(CLASS_NUM, activation='softmax'))\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()\n","# Рекомендация: Попробуйте добавить Batch Normalization"],"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Обучение модели"],"metadata":{}},{"cell_type":"markdown","source":["Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель. Также добавим EarlyStopping и ReduceLROnPlateau для ранее прерывания переобучения."],"metadata":{}},{"cell_type":"code","source":["checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\n","earlystop = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.25,\n","                              patience=2,\n","                              min_lr=0.0000001,\n","                              verbose=1,\n","                              mode='auto')\n","# Наши колбэки модели\n","callbacks_list = [checkpoint, earlystop, reduce_lr]\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Обучаем:"],"metadata":{}},{"cell_type":"code","source":["# Обучаем базовую модель\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch = len(train_generator),\n","        validation_data = test_generator, \n","        validation_steps = len(test_generator),\n","        epochs = EPOCHS,\n","        callbacks = callbacks_list\n",")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\n","model.save('../working/model_last.hdf5')\n","model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["В Итоге на первом прогоне точность нашей модели составила 73%. \n","Достойный результат для фиксированных весов базовой модели.    \n","Посмотрим графики обучения:"],"metadata":{}},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"source":["# Fine-Tuning\n","Стратегия обучения будет следующей:\n","* на первом этапе обучаем только голову\n","* на втором этапе обучаем 50% слоев\n","* на третьем этапе обучаем 100% слоев\n","* на четвертом этапе увеличиваем разрешение изображения до 512х512 и дообучаем на меньшем объеме аугментаций."],"cell_type":"markdown","metadata":{}},{"cell_type":"markdown","source":["\n","## STEP 2"],"metadata":{}},{"cell_type":"code","source":["# Проверим количество слоев в нашей базовой модели\n","print(\"Количество слоев в base model: \", len(base_model.layers))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Попробуем файн-тюнинг на половине слоев"],"metadata":{}},{"cell_type":"code","source":["base_model.trainable = True\n","\n","# Fine-tune\n","fine_tune_at = len(base_model.layers)//2\n","\n","# Заморозим все слои до fine_tune\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Количество обучаемых параметров: {len(base_model.trainable_variables)}')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Проверим статус слоев на trainable\n","for layer in model.layers:\n","    print(layer, layer.trainable)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Уменьшим LR и скомпилим новую модель\n","LR=1e-4\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Проверим текущий скор на тесте\n","scores = model.evaluate(test_generator, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обучаем\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n","        validation_data = test_generator, \n","        validation_steps = test_generator.samples//test_generator.batch_size,\n","        epochs = 10,\n","        callbacks = callbacks_list\n",")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\n","model.save('../working/model_step2.hdf5')\n","model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 3"],"metadata":{}},{"cell_type":"code","source":["# Добиваем обучение модели\n","base_model.trainable = True"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Еще сильнее понижаем LR\n","LR=1e-5\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обучаем\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n","        validation_data = test_generator, \n","        validation_steps = test_generator.samples//test_generator.batch_size,\n","        epochs = 10,\n","        callbacks = callbacks_list\n",")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('../working/model_step3.hdf5')\n","model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = model.evaluate(test_generator, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 4\n","На данном шаге мы увеличиваем разрешение изображения и уменьшаем количество аугментаций"],"metadata":{}},{"cell_type":"code","source":["EPOCHS               = 8\n","BATCH_SIZE           = 4 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\n","LR                   = 1e-5\n","\n","IMG_SIZE             = 512\n","IMG_CHANNELS         = 3\n","input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    rotation_range = 5,\n","    #width_shift_range=0.1,\n","    #height_shift_range=0.1,\n","    validation_split=VAL_SPLIT, # set validation split\n","    horizontal_flip=False)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(\n","    PATH+'train/',      # директория где расположены папки с картинками \n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=True, seed=RANDOM_SEED,\n","    subset='training') # set as training data\n","\n","test_generator = train_datagen.flow_from_directory(\n","    PATH+'train/',\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=True, seed=RANDOM_SEED,\n","    subset='validation') # set as validation data\n","\n","test_sub_generator = test_datagen.flow_from_dataframe( \n","    dataframe=sample_submission,\n","    directory=PATH+'test_upload/',\n","    x_col=\"Id\",\n","    y_col=None,\n","    shuffle=False,\n","    class_mode=None,\n","    seed=RANDOM_SEED,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n","base_model = efn.EfficientNetB5(weights='imagenet', include_top=False, input_shape = input_shape)\n","base_model.trainable = True"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обучаем\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n","        validation_data = test_generator, \n","        validation_steps = test_generator.samples//test_generator.batch_size,\n","        epochs = EPOCHS,\n","        callbacks = callbacks_list\n",")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('../working/model_step4.hdf5')\n","model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = model.evaluate(test_generator, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Предсказание IMG_SIZE RISE"],"metadata":{}},{"cell_type":"code","source":["test_sub_generator.samples"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sub_generator.reset()\n","predictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n","predictions = np.argmax(predictions, axis=-1) #multiple categories\n","label_map = (train_generator.class_indices)\n","label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n","predictions = [label_map[k] for k in predictions]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filenames_with_dir=test_sub_generator.filenames\n","submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n","submission['Id'] = submission['Id'].replace('test_upload/','')\n","submission.to_csv('submission.csv', index=False)\n","print('Save submit')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test Time Augmentation"],"metadata":{}},{"cell_type":"code","source":["model.load_weights('best_model.hdf5')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    rotation_range = 5,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    validation_split=VAL_SPLIT, # set validation split\n","    horizontal_flip=False)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sub_generator = test_datagen.flow_from_dataframe( \n","    dataframe=sample_submission,\n","    directory=PATH+'test_upload/',\n","    x_col=\"Id\",\n","    y_col=None,\n","    shuffle=False,\n","    class_mode=None,\n","    seed=RANDOM_SEED,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tta_steps = 10\n","predictions = []\n","\n","for i in range(tta_steps):\n","    preds = model.predict(test_sub_generator, verbose=1) \n","    predictions.append(preds)\n","\n","pred = np.mean(predictions, axis=0)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = np.argmax(pred, axis=-1) #multiple categories\n","label_map = (train_generator.class_indices)\n","label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n","predictions = [label_map[k] for k in predictions]\n","filenames_with_dir=test_sub_generator.filenames\n","submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, \n","                          columns=['Id', 'Category'])\n","\n","submission['Id'] = submission['Id'].replace('test_upload/','')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = model.evaluate(test_generator, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission.to_csv('submission_TTA.csv', index=False)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clean PATH\n","import shutil\n","shutil.rmtree(PATH)"],"metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"source":["## Чего удалось добиться в этом задании?\n","* Провели fine-tuning модели\n","* Выполнили TTA\n","* Добавили BatchNormalization в голову\n","* Использовали библиотеку albumentations для аугментации данных\n","* Использовали различные Callbacks\n","* Попробовали разные модели Xception, EfficientNet\n","## Чего не успели?\n","Стоить отметить, что 1 прогон ноутбука занимает 6 часов, поэтому не успел:\n","* Подобрать параметры головы при помощи Keras tuner\n","* Обогатить датасет классами на которых модель больше всего ошибается\n","* Поиграться с параметрами оптимизатора\n","\n","<b>Итоговый score: 97.438</b>"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}