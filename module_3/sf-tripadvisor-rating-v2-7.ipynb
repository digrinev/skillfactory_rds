{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n",
    "**По ходу задачи:**\n",
    "* Прокачаем работу с pandas\n",
    "* Научимся работать с Kaggle Notebooks\n",
    "* Поймем как делать предобработку различных данных\n",
    "* Научимся работать с пропущенными данными (Nan)\n",
    "* Познакомимся с различными видами кодирования признаков\n",
    "* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n",
    "* И совсем немного затронем ML\n",
    "* И многое другое...   \n",
    "\n",
    "\n",
    "\n",
    "### И самое важное, все это вы сможете сделать самостоятельно!\n",
    "\n",
    "*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n",
    "**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n",
    "\n",
    "В контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Функция подсчета значений в столбце, содержащим данные с разделителем\n",
    "def sep_counter(dataset, column, sep=','):\n",
    "    ds = dataset[column].str.cat(sep=sep)\n",
    "    data_split = pd.Series(ds.split(sep))\n",
    "    info = data_split.value_counts(ascending=False)\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Получить список топовых слов\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=stopwords.words('english')).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "# Создать фичи из слов\n",
    "def create_top_word_feature(comment):\n",
    "    vec = CountVectorizer(stop_words=stopwords.words('english')).fit(comment)\n",
    "    bag_of_words = vec.transform(comment)\n",
    "\n",
    "    for key in vec.vocabulary_.keys():\n",
    "        if key in top_word_list:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Округляем ценку с шагом 0.5\n",
    "def norm_rank(rank):\n",
    "    return (np.round(rank * 2.0) / 2)\n",
    "\n",
    "\n",
    "# Анализ тональности отзыва\n",
    "def sentiment_analysis(text):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos_word_list = []\n",
    "    neu_word_list = []\n",
    "    neg_word_list = []\n",
    "\n",
    "    for word in text:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            neg_word_list.append(word)\n",
    "        else:\n",
    "            neu_word_list.append(word)\n",
    "\n",
    "    # pos, neutral, neg\n",
    "    return len(pos_word_list), len(neu_word_list), len(neg_word_list)\n",
    "\n",
    "\n",
    "# Получаем бинарные признаки из признака, содержащего списки\n",
    "def get_binary_dummies(data, column):\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "    # Бинарные метки\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    expandedLabelData = mlb.fit_transform(data[column])\n",
    "    labelClasses = mlb.classes_\n",
    "\n",
    "    # Создаем датафрэйм бинарных признаков\n",
    "    expandedLabels = pd.DataFrame(expandedLabelData, columns=labelClasses)\n",
    "\n",
    "    return expandedLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('main_task.csv')\n",
    "df_test = pd.read_csv('kaggle_task.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 10 columns):\n",
      "Restaurant_id        40000 non-null object\n",
      "City                 40000 non-null object\n",
      "Cuisine Style        30717 non-null object\n",
      "Ranking              40000 non-null float64\n",
      "Rating               40000 non-null float64\n",
      "Price Range          26114 non-null object\n",
      "Number of Reviews    37457 non-null float64\n",
      "Reviews              40000 non-null object\n",
      "URL_TA               40000 non-null object\n",
      "ID_TA                40000 non-null object\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_5569</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['European', 'French', 'International']</td>\n",
       "      <td>5570.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[['Good food at your doorstep', 'A good hotel ...</td>\n",
       "      <td>/Restaurant_Review-g187147-d1912643-Reviews-R_...</td>\n",
       "      <td>d1912643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1535</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[['Unique cuisine', 'Delicious Nepalese food']...</td>\n",
       "      <td>/Restaurant_Review-g189852-d7992032-Reviews-Bu...</td>\n",
       "      <td>d7992032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_352</td>\n",
       "      <td>London</td>\n",
       "      <td>['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>688.0</td>\n",
       "      <td>[['Catch up with friends', 'Not exceptional'],...</td>\n",
       "      <td>/Restaurant_Review-g186338-d8632781-Reviews-RO...</td>\n",
       "      <td>d8632781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3456</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187323-d1358776-Reviews-Es...</td>\n",
       "      <td>d1358776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_615</td>\n",
       "      <td>Munich</td>\n",
       "      <td>['German', 'Central European', 'Vegetarian Fri...</td>\n",
       "      <td>621.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[['Best place to try a Bavarian food', 'Nice b...</td>\n",
       "      <td>/Restaurant_Review-g187309-d6864963-Reviews-Au...</td>\n",
       "      <td>d6864963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id       City                                      Cuisine Style  \\\n",
       "0       id_5569      Paris            ['European', 'French', 'International']   \n",
       "1       id_1535  Stockholm                                                NaN   \n",
       "2        id_352     London  ['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...   \n",
       "3       id_3456     Berlin                                                NaN   \n",
       "4        id_615     Munich  ['German', 'Central European', 'Vegetarian Fri...   \n",
       "\n",
       "   Ranking  Rating Price Range  Number of Reviews  \\\n",
       "0   5570.0     3.5    $$ - $$$              194.0   \n",
       "1   1537.0     4.0         NaN               10.0   \n",
       "2    353.0     4.5        $$$$              688.0   \n",
       "3   3458.0     5.0         NaN                3.0   \n",
       "4    621.0     4.0    $$ - $$$               84.0   \n",
       "\n",
       "                                             Reviews  \\\n",
       "0  [['Good food at your doorstep', 'A good hotel ...   \n",
       "1  [['Unique cuisine', 'Delicious Nepalese food']...   \n",
       "2  [['Catch up with friends', 'Not exceptional'],...   \n",
       "3                                           [[], []]   \n",
       "4  [['Best place to try a Bavarian food', 'Nice b...   \n",
       "\n",
       "                                              URL_TA     ID_TA  \n",
       "0  /Restaurant_Review-g187147-d1912643-Reviews-R_...  d1912643  \n",
       "1  /Restaurant_Review-g189852-d7992032-Reviews-Bu...  d7992032  \n",
       "2  /Restaurant_Review-g186338-d8632781-Reviews-RO...  d8632781  \n",
       "3  /Restaurant_Review-g187323-d1358776-Reviews-Es...  d1358776  \n",
       "4  /Restaurant_Review-g187309-d6864963-Reviews-Au...  d6864963  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 9 columns):\n",
      "Restaurant_id        10000 non-null object\n",
      "City                 10000 non-null object\n",
      "Cuisine Style        7693 non-null object\n",
      "Ranking              10000 non-null float64\n",
      "Price Range          6525 non-null object\n",
      "Number of Reviews    9343 non-null float64\n",
      "Reviews              9998 non-null object\n",
      "URL_TA               10000 non-null object\n",
      "ID_TA                10000 non-null object\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 703.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['Bar', 'Pub']</td>\n",
       "      <td>12963.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187147-d10746918-Reviews-L...</td>\n",
       "      <td>d10746918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>['European', 'Scandinavian', 'Gluten Free Opti...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>97.0</td>\n",
       "      <td>[['Very good reviews!', 'Fine dining in Hakani...</td>\n",
       "      <td>/Restaurant_Review-g189934-d6674944-Reviews-Ra...</td>\n",
       "      <td>d6674944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>['Vegetarian Friendly']</td>\n",
       "      <td>810.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[['Better than the Links', 'Ivy Black'], ['12/...</td>\n",
       "      <td>/Restaurant_Review-g186525-d13129638-Reviews-B...</td>\n",
       "      <td>d13129638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3</td>\n",
       "      <td>London</td>\n",
       "      <td>['Italian', 'Mediterranean', 'European', 'Vege...</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>202.0</td>\n",
       "      <td>[['Most exquisite', 'Delicious and authentic']...</td>\n",
       "      <td>/Restaurant_Review-g186338-d680417-Reviews-Qui...</td>\n",
       "      <td>d680417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_4</td>\n",
       "      <td>Bratislava</td>\n",
       "      <td>['Italian', 'Mediterranean', 'European', 'Seaf...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[['Always the best in bratislava', 'Very good ...</td>\n",
       "      <td>/Restaurant_Review-g274924-d1112354-Reviews-Ma...</td>\n",
       "      <td>d1112354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id        City  \\\n",
       "0          id_0       Paris   \n",
       "1          id_1    Helsinki   \n",
       "2          id_2   Edinburgh   \n",
       "3          id_3      London   \n",
       "4          id_4  Bratislava   \n",
       "\n",
       "                                       Cuisine Style  Ranking Price Range  \\\n",
       "0                                     ['Bar', 'Pub']  12963.0    $$ - $$$   \n",
       "1  ['European', 'Scandinavian', 'Gluten Free Opti...    106.0    $$ - $$$   \n",
       "2                            ['Vegetarian Friendly']    810.0    $$ - $$$   \n",
       "3  ['Italian', 'Mediterranean', 'European', 'Vege...   1669.0        $$$$   \n",
       "4  ['Italian', 'Mediterranean', 'European', 'Seaf...     37.0        $$$$   \n",
       "\n",
       "   Number of Reviews                                            Reviews  \\\n",
       "0                4.0                                           [[], []]   \n",
       "1               97.0  [['Very good reviews!', 'Fine dining in Hakani...   \n",
       "2               28.0  [['Better than the Links', 'Ivy Black'], ['12/...   \n",
       "3              202.0  [['Most exquisite', 'Delicious and authentic']...   \n",
       "4              162.0  [['Always the best in bratislava', 'Very good ...   \n",
       "\n",
       "                                              URL_TA      ID_TA  \n",
       "0  /Restaurant_Review-g187147-d10746918-Reviews-L...  d10746918  \n",
       "1  /Restaurant_Review-g189934-d6674944-Reviews-Ra...   d6674944  \n",
       "2  /Restaurant_Review-g186525-d13129638-Reviews-B...  d13129638  \n",
       "3  /Restaurant_Review-g186338-d680417-Reviews-Qui...    d680417  \n",
       "4  /Restaurant_Review-g274924-d1112354-Reviews-Ma...   d1112354  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id  Rating\n",
       "0          id_0     2.0\n",
       "1          id_1     2.5\n",
       "2          id_2     4.0\n",
       "3          id_3     1.0\n",
       "4          id_4     4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      "Restaurant_id    10000 non-null object\n",
      "Rating           10000 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 156.3+ KB\n"
     ]
    }
   ],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      "Restaurant_id        50000 non-null object\n",
      "City                 50000 non-null object\n",
      "Cuisine Style        38410 non-null object\n",
      "Ranking              50000 non-null float64\n",
      "Price Range          32639 non-null object\n",
      "Number of Reviews    46800 non-null float64\n",
      "Reviews              49998 non-null object\n",
      "URL_TA               50000 non-null object\n",
      "ID_TA                50000 non-null object\n",
      "sample               50000 non-null int64\n",
      "Rating               50000 non-null float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>sample</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25980</th>\n",
       "      <td>id_2655</td>\n",
       "      <td>London</td>\n",
       "      <td>['Seafood', 'British']</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>237.0</td>\n",
       "      <td>[['First visit', 'Lovely!'], ['12/04/2017', '0...</td>\n",
       "      <td>/Restaurant_Review-g186338-d1010152-Reviews-Ar...</td>\n",
       "      <td>d1010152</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>id_9253</td>\n",
       "      <td>London</td>\n",
       "      <td>['Italian', 'Mediterranean', 'European', 'Vege...</td>\n",
       "      <td>8109.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[['Lovely dinner', 'Lovely Resturant to social...</td>\n",
       "      <td>/Restaurant_Review-g186338-d12032631-Reviews-R...</td>\n",
       "      <td>d12032631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23698</th>\n",
       "      <td>id_12472</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12482.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[['Good as convenient when in the area', \"Best...</td>\n",
       "      <td>/Restaurant_Review-g186338-d8613555-Reviews-Ch...</td>\n",
       "      <td>d8613555</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11084</th>\n",
       "      <td>id_5787</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187323-d11945680-Reviews-L...</td>\n",
       "      <td>d11945680</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44114</th>\n",
       "      <td>id_1957</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>['Austrian', 'European']</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>$</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[['vienna in june 2017', 'The house dish is a ...</td>\n",
       "      <td>/Restaurant_Review-g190454-d6889864-Reviews-Do...</td>\n",
       "      <td>d6889864</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id    City  \\\n",
       "25980       id_2655  London   \n",
       "9253        id_9253  London   \n",
       "23698      id_12472  London   \n",
       "11084       id_5787  Berlin   \n",
       "44114       id_1957  Vienna   \n",
       "\n",
       "                                           Cuisine Style  Ranking Price Range  \\\n",
       "25980                             ['Seafood', 'British']   2660.0    $$ - $$$   \n",
       "9253   ['Italian', 'Mediterranean', 'European', 'Vege...   8109.0    $$ - $$$   \n",
       "23698                                                NaN  12482.0         NaN   \n",
       "11084                                                NaN   5789.0         NaN   \n",
       "44114                           ['Austrian', 'European']   1959.0           $   \n",
       "\n",
       "       Number of Reviews                                            Reviews  \\\n",
       "25980              237.0  [['First visit', 'Lovely!'], ['12/04/2017', '0...   \n",
       "9253                21.0  [['Lovely dinner', 'Lovely Resturant to social...   \n",
       "23698                2.0  [['Good as convenient when in the area', \"Best...   \n",
       "11084                2.0                                           [[], []]   \n",
       "44114               10.0  [['vienna in june 2017', 'The house dish is a ...   \n",
       "\n",
       "                                                  URL_TA      ID_TA  sample  \\\n",
       "25980  /Restaurant_Review-g186338-d1010152-Reviews-Ar...   d1010152       1   \n",
       "9253   /Restaurant_Review-g186338-d12032631-Reviews-R...  d12032631       0   \n",
       "23698  /Restaurant_Review-g186338-d8613555-Reviews-Ch...   d8613555       1   \n",
       "11084  /Restaurant_Review-g187323-d11945680-Reviews-L...  d11945680       1   \n",
       "44114  /Restaurant_Review-g190454-d6889864-Reviews-Do...   d6889864       1   \n",
       "\n",
       "       Rating  \n",
       "25980     4.0  \n",
       "9253      0.0  \n",
       "23698     4.0  \n",
       "11084     3.0  \n",
       "44114     4.5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[['Very good reviews!', 'Fine dining in Hakaniemi'], ['12/05/2017', '10/29/2017']]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data\n",
    "Обычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработка NAN \n",
    "У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \n",
    "По этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для примера я возьму столбец Number of Reviews\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        1\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       1\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "49970    0\n",
       "49971    0\n",
       "49972    1\n",
       "49973    0\n",
       "49974    0\n",
       "49975    0\n",
       "49976    0\n",
       "49977    0\n",
       "49978    0\n",
       "49979    0\n",
       "49980    0\n",
       "49981    0\n",
       "49982    0\n",
       "49983    0\n",
       "49984    0\n",
       "49985    0\n",
       "49986    1\n",
       "49987    0\n",
       "49988    1\n",
       "49989    1\n",
       "49990    0\n",
       "49991    0\n",
       "49992    0\n",
       "49993    0\n",
       "49994    0\n",
       "49995    0\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: Number_of_Reviews_isNAN, Length: 50000, dtype: uint8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Number_of_Reviews_isNAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее заполняем пропуски 0, вы можете попробовать заполнением средним или средним по городу и тд...\n",
    "data['Number of Reviews'].fillna(data['Number of Reviews'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка признаков\n",
    "Для начала посмотрим какие признаки у нас могут быть категориальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant_id              13094\n",
       "City                          31\n",
       "Cuisine Style              10732\n",
       "Ranking                    12975\n",
       "Price Range                    4\n",
       "Number of Reviews           1574\n",
       "Reviews                    41858\n",
       "URL_TA                     49963\n",
       "ID_TA                      49963\n",
       "sample                         2\n",
       "Rating                        10\n",
       "Number_of_Reviews_isNAN        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Категориальными** признаками здесь являются **City** и **Cuisine Style**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кодирования категориальных признаков есть множество подходов:\n",
    "* Label Encoding\n",
    "* One-Hot Encoding\n",
    "* Target Encoding\n",
    "* Hashing\n",
    "\n",
    "Выбор кодирования зависит от признака и выбраной модели.\n",
    "Не будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n",
    "![](https://i.imgur.com/mtimFxh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним оригинальный столбец City для дальнейшей обработки\n",
    "data['City_Orig'] = data['City']\n",
    "\n",
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>sample</th>\n",
       "      <th>Rating</th>\n",
       "      <th>...</th>\n",
       "      <th>City_Oporto</th>\n",
       "      <th>City_Oslo</th>\n",
       "      <th>City_Paris</th>\n",
       "      <th>City_Prague</th>\n",
       "      <th>City_Rome</th>\n",
       "      <th>City_Stockholm</th>\n",
       "      <th>City_Vienna</th>\n",
       "      <th>City_Warsaw</th>\n",
       "      <th>City_Zurich</th>\n",
       "      <th>City_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>['Bar', 'Pub']</td>\n",
       "      <td>12963.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187147-d10746918-Reviews-L...</td>\n",
       "      <td>d10746918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>['European', 'Scandinavian', 'Gluten Free Opti...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>97.0</td>\n",
       "      <td>[['Very good reviews!', 'Fine dining in Hakani...</td>\n",
       "      <td>/Restaurant_Review-g189934-d6674944-Reviews-Ra...</td>\n",
       "      <td>d6674944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2</td>\n",
       "      <td>['Vegetarian Friendly']</td>\n",
       "      <td>810.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[['Better than the Links', 'Ivy Black'], ['12/...</td>\n",
       "      <td>/Restaurant_Review-g186525-d13129638-Reviews-B...</td>\n",
       "      <td>d13129638</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3</td>\n",
       "      <td>['Italian', 'Mediterranean', 'European', 'Vege...</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>202.0</td>\n",
       "      <td>[['Most exquisite', 'Delicious and authentic']...</td>\n",
       "      <td>/Restaurant_Review-g186338-d680417-Reviews-Qui...</td>\n",
       "      <td>d680417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_4</td>\n",
       "      <td>['Italian', 'Mediterranean', 'European', 'Seaf...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[['Always the best in bratislava', 'Very good ...</td>\n",
       "      <td>/Restaurant_Review-g274924-d1112354-Reviews-Ma...</td>\n",
       "      <td>d1112354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id                                      Cuisine Style  Ranking  \\\n",
       "0          id_0                                     ['Bar', 'Pub']  12963.0   \n",
       "1          id_1  ['European', 'Scandinavian', 'Gluten Free Opti...    106.0   \n",
       "2          id_2                            ['Vegetarian Friendly']    810.0   \n",
       "3          id_3  ['Italian', 'Mediterranean', 'European', 'Vege...   1669.0   \n",
       "4          id_4  ['Italian', 'Mediterranean', 'European', 'Seaf...     37.0   \n",
       "\n",
       "  Price Range  Number of Reviews  \\\n",
       "0    $$ - $$$                4.0   \n",
       "1    $$ - $$$               97.0   \n",
       "2    $$ - $$$               28.0   \n",
       "3        $$$$              202.0   \n",
       "4        $$$$              162.0   \n",
       "\n",
       "                                             Reviews  \\\n",
       "0                                           [[], []]   \n",
       "1  [['Very good reviews!', 'Fine dining in Hakani...   \n",
       "2  [['Better than the Links', 'Ivy Black'], ['12/...   \n",
       "3  [['Most exquisite', 'Delicious and authentic']...   \n",
       "4  [['Always the best in bratislava', 'Very good ...   \n",
       "\n",
       "                                              URL_TA      ID_TA  sample  \\\n",
       "0  /Restaurant_Review-g187147-d10746918-Reviews-L...  d10746918       0   \n",
       "1  /Restaurant_Review-g189934-d6674944-Reviews-Ra...   d6674944       0   \n",
       "2  /Restaurant_Review-g186525-d13129638-Reviews-B...  d13129638       0   \n",
       "3  /Restaurant_Review-g186338-d680417-Reviews-Qui...    d680417       0   \n",
       "4  /Restaurant_Review-g274924-d1112354-Reviews-Ma...   d1112354       0   \n",
       "\n",
       "   Rating  ...  City_Oporto City_Oslo  City_Paris  City_Prague  City_Rome  \\\n",
       "0     0.0  ...            0         0           1            0          0   \n",
       "1     0.0  ...            0         0           0            0          0   \n",
       "2     0.0  ...            0         0           0            0          0   \n",
       "3     0.0  ...            0         0           0            0          0   \n",
       "4     0.0  ...            0         0           0            0          0   \n",
       "\n",
       "   City_Stockholm  City_Vienna  City_Warsaw  City_Zurich  City_nan  \n",
       "0               0            0            0            0         0  \n",
       "1               0            0            0            0         0  \n",
       "2               0            0            0            0         0  \n",
       "3               0            0            0            0         0  \n",
       "4               0            0            0            0         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>sample</th>\n",
       "      <th>Rating</th>\n",
       "      <th>...</th>\n",
       "      <th>City_Oporto</th>\n",
       "      <th>City_Oslo</th>\n",
       "      <th>City_Paris</th>\n",
       "      <th>City_Prague</th>\n",
       "      <th>City_Rome</th>\n",
       "      <th>City_Stockholm</th>\n",
       "      <th>City_Vienna</th>\n",
       "      <th>City_Warsaw</th>\n",
       "      <th>City_Zurich</th>\n",
       "      <th>City_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49246</th>\n",
       "      <td>id_5419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5422.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187849-d8070307-Reviews-Pi...</td>\n",
       "      <td>d8070307</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34908</th>\n",
       "      <td>id_4942</td>\n",
       "      <td>['Cafe', 'Italian', 'Mediterranean', 'European']</td>\n",
       "      <td>4943.0</td>\n",
       "      <td>$</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[['Great breakfast', 'Close to hotel, reasonab...</td>\n",
       "      <td>/Restaurant_Review-g187791-d7158952-Reviews-Ca...</td>\n",
       "      <td>d7158952</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28038</th>\n",
       "      <td>id_3254</td>\n",
       "      <td>['European', 'Czech']</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[['Famous in Cathedral', 'Old classic'], ['04/...</td>\n",
       "      <td>/Restaurant_Review-g274707-d694871-Reviews-Res...</td>\n",
       "      <td>d694871</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36390</th>\n",
       "      <td>id_2803</td>\n",
       "      <td>['Asian', 'Cambodian', 'French', 'Fusion']</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>$</td>\n",
       "      <td>56.0</td>\n",
       "      <td>[['Great cambodian fresh food- excellent valu....</td>\n",
       "      <td>/Restaurant_Review-g187147-d8663789-Reviews-To...</td>\n",
       "      <td>d8663789</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>id_4199</td>\n",
       "      <td>['Turkish', 'Middle Eastern']</td>\n",
       "      <td>4202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187849-d9455589-Reviews-Po...</td>\n",
       "      <td>d9455589</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id                                     Cuisine Style  \\\n",
       "49246       id_5419                                               NaN   \n",
       "34908       id_4942  ['Cafe', 'Italian', 'Mediterranean', 'European']   \n",
       "28038       id_3254                             ['European', 'Czech']   \n",
       "36390       id_2803        ['Asian', 'Cambodian', 'French', 'Fusion']   \n",
       "14142       id_4199                     ['Turkish', 'Middle Eastern']   \n",
       "\n",
       "       Ranking Price Range  Number of Reviews  \\\n",
       "49246   5422.0         NaN                5.0   \n",
       "34908   4943.0           $               70.0   \n",
       "28038   3261.0    $$ - $$$               25.0   \n",
       "36390   2804.0           $               56.0   \n",
       "14142   4202.0         NaN               11.0   \n",
       "\n",
       "                                                 Reviews  \\\n",
       "49246                                           [[], []]   \n",
       "34908  [['Great breakfast', 'Close to hotel, reasonab...   \n",
       "28038  [['Famous in Cathedral', 'Old classic'], ['04/...   \n",
       "36390  [['Great cambodian fresh food- excellent valu....   \n",
       "14142                                           [[], []]   \n",
       "\n",
       "                                                  URL_TA     ID_TA  sample  \\\n",
       "49246  /Restaurant_Review-g187849-d8070307-Reviews-Pi...  d8070307       1   \n",
       "34908  /Restaurant_Review-g187791-d7158952-Reviews-Ca...  d7158952       1   \n",
       "28038  /Restaurant_Review-g274707-d694871-Reviews-Res...   d694871       1   \n",
       "36390  /Restaurant_Review-g187147-d8663789-Reviews-To...  d8663789       1   \n",
       "14142  /Restaurant_Review-g187849-d9455589-Reviews-Po...  d9455589       1   \n",
       "\n",
       "       Rating  ...  City_Oporto City_Oslo  City_Paris  City_Prague  City_Rome  \\\n",
       "49246     4.0  ...            0         0           0            0          0   \n",
       "34908     4.0  ...            0         0           0            0          1   \n",
       "28038     3.5  ...            0         0           0            1          0   \n",
       "36390     4.5  ...            0         0           1            0          0   \n",
       "14142     3.5  ...            0         0           0            0          0   \n",
       "\n",
       "       City_Stockholm  City_Vienna  City_Warsaw  City_Zurich  City_nan  \n",
       "49246               0            0            0            0         0  \n",
       "34908               0            0            0            0         0  \n",
       "28038               0            0            0            0         0  \n",
       "36390               0            0            0            0         0  \n",
       "14142               0            0            0            0         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возьмем следующий признак \"Price Range\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$$ - $$$    23041\n",
       "$            7816\n",
       "$$$$         1782\n",
       "Name: Price Range, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По описанию 'Price Range' это - Цены в ресторане.  \n",
    "Их можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  \n",
    "*Попробуйте сделать обработку этого признака уже самостоятельно!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваша обработка 'Price Range'\n",
    "price_range = {'$': 50, '$$ - $$$': 100, '$$$$': 150}\n",
    "\n",
    "# Создадим признак пропусков\n",
    "data['Price Range_isNaN'] = pd.isna(data['Price Range']).astype('uint8')\n",
    "\n",
    "# Заполним пропуски самым частым значением\n",
    "data['Price Range'] = data['Price Range'].fillna('$$ - $$$')\n",
    "\n",
    "# Закодируем Price Range через LabelEncoding\n",
    "data['Price Range'] = data['Price Range'].replace(price_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для некоторых алгоритмов МЛ даже для не категориальных признаков можно применить One-Hot Encoding, и это может улучшить качество модели. Пробуйте разные подходы к кодированию признака - никто не знает заранее, что может взлететь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработать другие признаки вы должны самостоятельно!\n",
    "Для обработки других признаков вам возможно придется даже написать свою функцию, а может даже и не одну, но в этом и есть ваша практика в этом модуле!     \n",
    "Следуя подсказкам в модуле вы сможете более подробно узнать, как сделать эти приобразования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33605    [['tasty and affordable Japanese food in Pari....\n",
      "Name: Reviews, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['Reviews'].sample())\n",
    "\n",
    "# Пустой отзыв\n",
    "empty_review = {'[[], []]': \"[['None', 'None'], ['05/20/2000', '05/20/2000']]\"}\n",
    "\n",
    "# Создадим NaN признак\n",
    "data['Reviews_is_NaN'] = pd.isna(data['Reviews']).astype('uint8')\n",
    "\n",
    "# Заменим пустые отзывы\n",
    "data['Reviews'] = data['Reviews'].replace(empty_review)\n",
    "\n",
    "# Заполним пропуски\n",
    "data['Reviews'] = data['Reviews'].fillna(\"[['None', 'None'], ['05/20/2000', '05/20/2000']]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# Переведем отзывы в список\n",
    "def get_review_lastdate(reviews):\n",
    "    reviews_dates = literal_eval(reviews)[1]\n",
    "    \n",
    "    return reviews_dates[0]\n",
    "\n",
    "def get_review_prelastdate(reviews):\n",
    "    reviews_dates = literal_eval(reviews)[1]\n",
    "    \n",
    "    if len(reviews_dates) > 1:\n",
    "        return reviews_dates[1]\n",
    "    else: \n",
    "        return reviews_dates[0]\n",
    "    \n",
    "\n",
    "def get_review_lastcomment(reviews):\n",
    "    \n",
    "    reviews_text = literal_eval(reviews)[0]\n",
    "    \n",
    "    return reviews_text[0]  \n",
    "\n",
    "\n",
    "def get_review_prelastcomment(reviews):\n",
    "    reviews_text = literal_eval(reviews)[0]\n",
    "    \n",
    "    if len(reviews_text) > 1:\n",
    "        return reviews_text[1]\n",
    "    else:\n",
    "        return reviews_text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В отзывах есть запись с NaN нужно ее поправить\n",
    "#data.loc[data['Reviews'].str.contains(', nan'), 'Reviews'] = \"[['Will certainly be back', 'None'], ['11/26/2017', '07/27/2017']]\"\n",
    "#data.loc[data['Reviews'].str.contains('nan, '), 'Reviews'] = \"[['None', 'Good food with decent service'], ['11/21/2017', '07/21/2017']]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.Name object at 0x0000017F13D79128>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-abbe0ead2fb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Создаем признаки из Review\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Последний отзыв\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'last_comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_review_lastcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Предпоследний отзыв\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prelast_comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_review_prelastcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-db7776034e08>\u001b[0m in \u001b[0;36mget_review_lastcomment\u001b[1;34m(reviews)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_review_lastcomment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mreviews_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreviews_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed node or string: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnaryOp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mUAdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUSub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: <_ast.Name object at 0x0000017F13D79128>"
     ]
    }
   ],
   "source": [
    "# Создаем признаки из Review\n",
    "# Последний отзыв\n",
    "data['last_comment'] = data['Reviews'].apply(get_review_lastcomment)\n",
    "# Предпоследний отзыв\n",
    "data['prelast_comment'] = data['Reviews'].apply(get_review_prelastcomment)\n",
    "# Дата последнего отзыва\n",
    "data['last_comment_date'] = data['Reviews'].apply(get_review_lastdate)\n",
    "# Дата предпоследнего отзыва\n",
    "data['prelast_comment_date'] = data['Reviews'].apply(get_review_prelastdate)\n",
    "\n",
    "# Переведем даты в datetime\n",
    "data['last_comment_date'] = pd.to_datetime(data['last_comment_date'])\n",
    "data['prelast_comment_date'] = pd.to_datetime(data['prelast_comment_date'])\n",
    "\n",
    "# Разница в днях между отзывами\n",
    "data['days_between_reviews'] = abs((data['last_comment_date'] - data['prelast_comment_date']).dt.days)\n",
    "\n",
    "# Разница текущей даты с последним отзывом\n",
    "data['days_between_today_and_lastreview'] = (pd.to_datetime('today') - data['last_comment_date']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка отзывов\n",
    "def review_preprocessing2(review):       \n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    review = re.sub(re.compile('<.*?>'), '', review)\n",
    "    review = re.sub('[^A-Za-z]+', ' ', review)\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(review)\n",
    "    \n",
    "    # Удаляем стоп-слова\n",
    "    review = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Лемматизация\n",
    "    review = [lemmatizer.lemmatize(word) for word in review]\n",
    "    \n",
    "    #review = ' '.join(review)\n",
    "    \n",
    "    return review\n",
    "\n",
    "# Комментарий\n",
    "data['cat_comments'] = data['last_comment'] + ' ' + data['prelast_comment']\n",
    "data['comments'] = data['cat_comments'].apply(lambda review: review_preprocessing2(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим бинарные признаки из слов\n",
    "word_features = get_binary_dummies(data, 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отберем бинарные признаки, где количество повторений слова меньше 10\n",
    "cols_to_delete = word_features.sum()\n",
    "cols_to_delete = cols_to_delete[cols_to_delete < 50].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим эти признаки\n",
    "word_features = word_features.drop(cols_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим количество положительных, нейтральных, негативных слов в отзыве\n",
    "data['PNN'] = data['comments'].apply(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['PNN'].to_csv('pnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество позитивных слов\n",
    "data['Positive Words'] = data['PNN'].apply(lambda s: s[0])\n",
    "# Количество негативных слов\n",
    "data['Negative Words'] = data['PNN'].apply(lambda s: s[2])\n",
    "# Количество нейтральных слов\n",
    "data['Neutral Words'] = data['PNN'].apply(lambda s: s[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Положительных слов на город\n",
    "cities_pos_count = data.groupby('City_Orig')['Positive Words'].sum().to_dict()\n",
    "# Отрицательных слов на город\n",
    "cities_neg_count = data.groupby('City_Orig')['Negative Words'].sum().to_dict()\n",
    "# Нейтральных слов на город\n",
    "cities_neu_count = data.groupby('City_Orig')['Neutral Words'].sum().to_dict()\n",
    "\n",
    "data['City Positive Words'] = data['City_Orig'].apply(lambda s: cities_pos_count[s])\n",
    "data['City Negative Words'] = data['City_Orig'].apply(lambda s: cities_neg_count[s])\n",
    "data['City Neutral Words'] = data['City_Orig'].apply(lambda s: cities_neu_count[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доля положительных отзывов на город\n",
    "data['City Positive Percent'] = data['City Positive Words'] / (data['City Positive Words'] + data['City Negative Words'] + data['City Neutral Words'])\n",
    "\n",
    "# Доля отрицательных отзывов на город\n",
    "data['City Negative Percent'] = data['City Negative Words'] / (data['City Positive Words'] + data['City Negative Words'] + data['City Neutral Words'])\n",
    "\n",
    "# Доля нейтральных слов\n",
    "data['City Neutral Percent'] = data['City Neutral Words'] / (data['City Positive Words'] + data['City Negative Words'] + data['City Neutral Words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее количество отзывов на город\n",
    "mean_reviews = data.groupby('City_Orig')['Number of Reviews'].mean().to_dict()\n",
    "data['Mean Number of Reviews'] = data['City_Orig'].apply(lambda s: mean_reviews[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний чек на город\n",
    "#mean_price_range = data.groupby('City_Orig')['Price Range'].mean().to_dict()\n",
    "#data['Mean Price Range'] = data['City_Orig'].apply(lambda s: mean_price_range[s])\n",
    "#mean_price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обрабатываем Cuisine Style\n",
    "data['Cuisine Style'].isna().sum()\n",
    "\n",
    "# Создадим NaN признак\n",
    "data['Cuisine Style_is_NaN'] = pd.isna(data['Cuisine Style']).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски Cuisine Style значением Local (местная)\n",
    "data['Cuisine Style'] = data['Cuisine Style'].fillna(\"['Local']\")\n",
    "# Средний ранк ресторана в городе\n",
    "#data['Cuisine Style'].groupby('City_Orig')['Cuisine Style'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на данные в Cuisine Style\n",
    "data['Cuisine Style'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Почистим Cuisine Style\n",
    "#data['Cuisine Style'] = data['Cuisine Style'].apply(lambda s: s.replace('[', '').replace(']', '').replace(', ', ',') if not pd.isnull(s) else s)\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим фичу Cuisine Style Count - количество кухонь в ресторане"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cusine Style Count'] = data['Cuisine Style'].apply(lambda s: len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество кухонь в городе\n",
    "cusine_per_city = data.groupby('City_Orig')['Cusine Style Count'].sum().to_dict()\n",
    "data['Cuisine Per City'] = data['City_Orig'].apply(lambda s: cusine_per_city[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим бинарные признаки типов кухонь Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируем признак Cuisine Style в отдельный датафрэйм\n",
    "cuisine_pd = get_binary_dummies(data, 'Cuisine Style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В ресторане есть уникальная кухня\n",
    "unique_cuisine = ['Yunnan', 'Latvian', 'Burmese', 'Salvadoran', 'Xinjiang']\n",
    "\n",
    "for uc in unique_cuisine:\n",
    "    data['is_unique_cuisine'] = data.apply(lambda s: 1 if uc in s['Cuisine Style'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Есть веганская кухня\n",
    "vegan = ['Vegetarian Friendly', 'Vegan Options', 'Gluten Free Options']\n",
    "\n",
    "for veg in vegan:\n",
    "    data['is_vegan'] = data.apply(lambda s: 1 if veg in s['Cuisine Style'] else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Популярная кухня\n",
    "top_cuisine = ['European', 'Vegetarian Friendly', 'Italian', 'Mediterranean', 'French', 'Vegan Options', 'Bar', 'Spanish', 'Gluten Free Options', 'Pub']\n",
    "\n",
    "for top in top_cuisine:\n",
    "    data['is_popular_cuisine'] = data.apply(lambda s: 1 if top in s['Cuisine Style'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_pd.sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше мы присоединим эти данные к основному датасету при помощи pd.concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим признаки из City (население, столица)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City_Orig'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь города из Википедии вручную. Объемы не большие.\n",
    "city_dict = {\n",
    "    'London': {'population': 8908081, 'is_capital': True, 'country': 'England'},\n",
    "    'Paris': {'population': 2148327, 'is_capital': True, 'country': 'France'},\n",
    "    'Madrid': {'population': 3266126, 'is_capital': True, 'country': 'Spain'},\n",
    "    'Barcelona': {'population': 1636762, 'is_capital': False, 'country': 'Spain'},\n",
    "    'Berlin': {'population': 3644826, 'is_capital': True, 'country': 'Germany'},\n",
    "    'Milan': {'population': 1378689, 'is_capital': False, 'country': 'Italy'},\n",
    "    'Rome': {'population': 2870500, 'is_capital': True, 'country': 'Italy'},\n",
    "    'Prague': {'population': 1301132, 'is_capital': True, 'country': 'Czech'},\n",
    "    'Lisbon': {'population': 505526, 'is_capital': True, 'country': 'Portugal'},\n",
    "    'Vienna': {'population': 1897491, 'is_capital': True, 'country': 'Austria'},\n",
    "    'Amsterdam': {'population': 857713, 'is_capital': True, 'country': 'Netherlands'},\n",
    "    'Brussels': {'population': 1208542, 'is_capital': True, 'country': 'Belgium'},\n",
    "    'Hamburg': {'population': 1899160, 'is_capital': False, 'country': 'Germany'},\n",
    "    'Munich': {'population': 1471508, 'is_capital': False, 'country': 'Germany'},\n",
    "    'Lyon': {'population': 506615, 'is_capital': False, 'country': 'France'},\n",
    "    'Stockholm': {'population': 961609, 'is_capital': True, 'country': 'Sweden'},\n",
    "    'Budapest': {'population': 1752286, 'is_capital': True, 'country': 'Hungary'},\n",
    "    'Warsaw': {'population': 1790658, 'is_capital': True, 'country': 'Poland'},\n",
    "    'Dublin': {'population': 1173179, 'is_capital': True, 'country': 'Ireland'},\n",
    "    'Copenhagen': {'population': 615993, 'is_capital': True, 'country': 'Denmark'},\n",
    "    'Athens': {'population': 664046, 'is_capital': True, 'country': 'Greece'},\n",
    "    'Edinburgh': {'population': 488100, 'is_capital': True, 'country': 'Scotland'},\n",
    "    'Zurich': {'population': 428737, 'is_capital': False, 'country': 'Switzerland'},\n",
    "    'Oporto': {'population': 237591, 'is_capital': False, 'country': 'Portugal'},\n",
    "    'Geneva': {'population': 200548, 'is_capital': False, 'country': 'Switzerland'},\n",
    "    'Krakow': {'population': 769498, 'is_capital': False, 'country': 'Poland'},\n",
    "    'Oslo': {'population': 673469, 'is_capital': True, 'country': 'Norway'},\n",
    "    'Helsinki': {'population':  643272, 'is_capital': True, 'country': 'Findland'},\n",
    "    'Bratislava': {'population': 437725, 'is_capital': True, 'country': 'Slovakia'},\n",
    "    'Luxembourg': {'population': 602005, 'is_capital': True, 'country': 'Luxembourg'},\n",
    "    'Ljubljana': {'population': 284355, 'is_capital': True, 'country': 'Slovenia'},\n",
    "    \n",
    "                                    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем признаки Population, Country, is_capital\n",
    "data['Population'] = data['City_Orig'].apply(lambda s: city_dict[s]['population'])\n",
    "data['Country'] = data['City_Orig'].apply(lambda s: city_dict[s]['country'])\n",
    "data['is_capital'] = data['City_Orig'].apply(lambda s: city_dict[s]['is_capital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируем название страны\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['Country'] = encoder.fit_transform(data['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество ресторанов в городе\n",
    "rests_num = data['City_Orig'].value_counts().to_dict()\n",
    "\n",
    "data['Restaurants Count'] = data['City_Orig'].apply(lambda s: rests_num[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим признак количества ресторанов на душу населения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RestIndex'] = data['Restaurants Count'] / data['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Относительный рейтинг ресторана\n",
    "data['Relative Ranking'] = data['Ranking'] / data['Restaurants Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний ранк ресторана в городе\n",
    "data['mean_ranking'] = data['Ranking']/data['City_Orig'].map(data.groupby(['City_Orig'])['Ranking'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_TA\n",
    "data['ID_TA_NUM'] = data['ID_TA'].apply(lambda s: s[1:]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ID_TA_NUM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зависимость места ресторана в городе от населения\n",
    "data['Relative Rank by Population'] = data['Relative Ranking']  / data['Population'] \n",
    "\n",
    "# Доля позитивных слов в отзыве\n",
    "data['PositiveWords in Reviews'] = data['Positive Words'] / data['Number of Reviews']\n",
    "\n",
    "# Как часто в городе оставляют отзывы\n",
    "data['NRP'] = data['Number of Reviews'] / data['Population']\n",
    "\n",
    "# Ранг ресторана с учетом частоты отзывов в городе\n",
    "data['WRR'] =  data['Relative Ranking']  *  data['NRP'] \n",
    "\n",
    "# Относительный разброс цены\n",
    "data['Relative Price Range'] = data['Price Range'] / data['Relative Ranking']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cs10.pikabu.ru/post_img/2018/09/06/11/1536261023140110012.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\n",
    "На этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\n",
    "В общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\n",
    "Понимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n",
    "![](https://miro.medium.com/max/2598/1*RXdMb7Uk6mGqWqPguHULaQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n",
    "\n",
    ">Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной относительно признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\n",
    "На этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "#sns.heatmap(data.drop(['sample'], axis=1).corr(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n",
    "* где больше Пицерий в Мадриде или Лондоне?\n",
    "* в каком городе кухня ресторанов более разнообразна?\n",
    "\n",
    "придумайте свои вопрос и найдите на него ответ в данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preproc = preproc_data(data)\n",
    "#df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "\n",
    "data = pd.concat([data, cuisine_pd, word_features], axis=1)\n",
    "\n",
    "train_data = data.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = data.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(X.select_dtypes(include=['object']).columns, axis=1)\n",
    "X = X.drop(X.select_dtypes(include=['datetime']).columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "y_pred_tt = y_pred\n",
    "\n",
    "# Небольшая компенсация ошибки\n",
    "alpha = 0.02\n",
    "y_pred_tt = y_pred_tt - alpha\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, norm_rank(y_pred_tt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(test_data.select_dtypes(include=['object']).columns, axis=1)\n",
    "test_data = test_data.drop(test_data.select_dtypes(include=['datetime']).columns, axis=1)\n",
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем значения предсказаний к правильному виду\n",
    "\n",
    "# Небольшая компенсация ошибки\n",
    "alpha = 0.02\n",
    "\n",
    "predict_submission = norm_rank(predict_submission - alpha)\n",
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "Или что делать, чтоб улучшить результат:\n",
    "* Обработать оставшиеся признаки в понятный для машины формат\n",
    "* Посмотреть, что еще можно извлечь из признаков\n",
    "* Сгенерировать новые признаки\n",
    "* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n",
    "* Подобрать состав признаков\n",
    "\n",
    "В общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
