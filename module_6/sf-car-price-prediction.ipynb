{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Регрессия](https://zr.ru/_ah/img/vgtv7RJ4pcu8y7Lq847wYw=s800 \"Предсказываем цены\")\n\n## Прогнозируем стоимость автомобиля по его характеристикам\n\n> По условиям соревнования обучающую выборку мы должны собрать сами. В данной работе использованы данные от **8.11.2020** с сайта auto.ru.\n\nЦелевой метрикой выбрана MAPE:\n\n$$\nMAPE = \\frac{100}{n}\\sum_i\\left \\| \\frac{y(i)-\\hat{y}(i)}{y} \\right \\|\n$$"},{"metadata":{},"cell_type":"markdown","source":"# Подкючаем библиотеки"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport shap # SHAPley\nimport secrets # rnd str generator\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import make_scorer\nfrom lightgbm import LGBMRegressor\nimport category_encoders as ce\nimport xgboost as xgb\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport lime\nimport lime.lime_tabular\n\nfrom sklearn.decomposition import PCA\nfrom collections import Counter\nimport joblib\nimport ast\n\nfrom catboost import Pool, CatBoostRegressor\n\nfrom pandas_profiling import ProfileReport\n\n# Загрузим собственные модули\nfrom shutil import copyfile\ncopyfile(src = \"../input/myutils/dshelper.py\", dst = \"../working/dshelper.py\")\nfrom dshelper import *\n\n## SKLEARN\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Константы "},{"metadata":{"trusted":true},"cell_type":"code","source":"VERSION    = 3\nDIR_TRAIN  = '../input/train-data/'\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%\n\n# CATBOOST\nITERATIONS = 5000\nLR         = 0.1\n\nRANDOM_SEED = 42\nN_FOLDS = 5\nCURRENT_YEAR = 2020\n\nFIGSIZE = (5, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отчеты по каждой CV модели\ndef show_models_report():\n    \n    frames = []\n    \n    for file in os.listdir():\n        if file.endswith('.frame'):\n            filename = file[:-6]\n            report = joblib.load(filename+'.frame')\n            num_cols = report.columns[report.columns.str.contains('FOLD_')]\n            report[num_cols] = report[num_cols] .astype('float64')\n            frames.append(report)\n        \n    return pd.DataFrame(pd.concat(frames))\n    \n# ROUND PREDS\ndef round_preds(y_pred, step=5000):\n    return np.array([step*round(x/step) for x in y_pred])\n\n# MAPE\ndef mean_absolute_percentage_error(y_true, y_pred, **kwargs): \n    y_true, y_pred = np.array(y_true), round_preds(np.array(y_pred))\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n# MAPE для отдельного наблюдения\ndef mape_per_row(y_true_col, y_pred_col):\n    return np.abs((y_true_col - y_pred_col) / y_true_col) * 100\n\n# Запуск модели через cross-val\ndef run_model_cv(model_func=None, X=None, y=None, sub_test=None, cv=5, random_state=42, name='basemodel', comment='', model_type='tree', target_encoding=False, te_cols=None):\n    # Попробуем нашу первую базовую модель на CatBoost через CV\n    sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n    submissions = pd.DataFrame(0,columns=[\"sub_1\"], index=sample_submission.index) # куда пишем предикты по каждой модели\n    \n    # OOF PREDS\n    oof_preds = np.zeros(X.shape[0])\n    \n    # Сохраняем рейтинг модели по каждому фолду\n    mape_cols = [f'FOLD_{col+1}' for col in range(cv)]\n    name_postfix = secrets.token_urlsafe(4)\n    mape = pd.DataFrame([[0 for _ in range(cv)]], columns=mape_cols, index=[name+name_postfix]) # пишем рейтинг по каждой модели\n    \n    feature_importance_df = pd.DataFrame()\n\n    score_ls = []\n    \n    # Пробуем разные сплиты\n    #splits = list(KFold(n_splits=cv, shuffle=True, random_state=random_state).split(X, y))\n    splits = list(StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state).split(X, y))\n\n\n    for idx, (train_idx, test_idx) in tqdm(enumerate(splits), total=cv,):\n        # use the indexes to extract the folds in the train and validation data\n        X_train, y_train, X_test, y_test = X.iloc[train_idx], y.iloc[train_idx], X.iloc[test_idx], y.iloc[test_idx]   \n            \n        # model func or estimator for this fold    \n        model = model_func(X_train, X_test, y_train, y_test)\n        # score model on test\n        test_predict = model.predict(X_test)\n        test_score = mean_absolute_percentage_error(y_test, test_predict)\n        score_ls.append(test_score)\n        \n        # OOF Predicts\n        oof_preds[test_idx] = test_predict\n        \n        fold_mape = mean_absolute_percentage_error(y_test, test_predict)\n        print(f\"{idx+1} Fold Test MAPE: {fold_mape:0.3f}\")\n        # Save mape to df\n        mape[f'FOLD_{idx+1}'] = f'{fold_mape:0.3f}'\n        \n        # submissions\n        submissions[f'sub_{idx+1}'] = model.predict(sub_test)\n        model_name = f'{name}_fold_{idx+1}.model'\n        joblib.dump(model, model_name)\n        #model.save_model(f'catboost_fold_{idx+1}.model')\n        \n        # Feature importances\n        if model_type == 'tree':\n            feature_importance = model.feature_importances_\n        elif model_type == 'lgbm':\n            feature_importance = model.feature_importance()\n        else:\n            feature_importance = 0.1\n            \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = X.columns\n        fold_importance_df[\"importance\"] = feature_importance\n        fold_importance_df[\"fold\"] = idx + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print(f'Mean Score: {np.mean(score_ls):0.3f}')\n    print(f'Std Score: {np.std(score_ls):0.4f}')\n    print(f'Max Score: {np.max(score_ls):0.3f}')\n    print(f'Min Score: {np.min(score_ls):0.3f}')\n    \n    mape['comment'] = comment\n    mape['mean'] = np.round(np.mean(score_ls), 3)\n    display(mape)\n\n    # Сохраним рейтинг модели\n    joblib.dump(mape, name+'_'+name_postfix+'_rating.frame')\n\n    return submissions, feature_importance_df, oof_preds\n\n\n# Объединяем трейн и тест\ndef merge_dataset(df_train, df_test):\n    df_train['sample'] = 1 # помечаем где у нас трейн\n    df_test['sample'] = 0 # помечаем где у нас тест\n    data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n\n    return data\n\n# Загрузка данных\ndef load_data(load_nlp=True):\n    '''\n        Loads our dataset\n        \n        - load_nlp - load NLP preprocessed description feature \n    '''\n    data = None\n    # Наши данные\n    df_test = pd.read_csv(DIR_TEST + 'test.csv')\n    df_train = pd.read_csv(DIR_TRAIN + 'train_data.csv', sep='|')\n\n    # Сразу удалим лишние колонки, которые есть в наших данных\n    df_train.drop(['currency', 'Комплектация'], axis=1, inplace=True)\n    \n    data = merge_dataset(df_train, df_test)\n    \n    data.super_gen = data.super_gen.fillna('{}')\n    data.super_gen = data.super_gen.map(ast.literal_eval)\n\n    \n    # Загружаем описание объявлений из файла\n    if load_nlp:\n        description = pd.read_csv(DIR_TRAIN+'description.csv', header=None, sep='\\n')\n        data.description = description[0].apply(lambda s: s.split(','))\n        data.description = data.description.fillna('nodata')\n    \n    return data\n    \n\n# Разделяем датасет на тест и трейн\ndef data_split(df):\n    X = df.query('sample == 1').drop(['sample'], axis=1)\n    X_sub = df.query('sample == 0').drop(['sample', 'price'], axis=1)\n    \n    return X, X_sub\n\n\n# Обработка датасета через пайплайн\ndef prepare_data_pipeline(data, processing_pipe):\n    '''\n        Return Processed DataFrame through pipeline\n\n        return: X, y, X_sub\n    '''\n    # Обработаем данные\n    processing_pipe = processing_pipe\n\n    # Проводим обработку отдельно для теста и трэйна, чтобы избежать даталиков\n    data = processing_pipe.fit_transform(data)\n    \n    # Разбиваем данные на трейн и тест\n    X, X_sub = data_split(data)\n\n    y = X.price\n    X = X.drop(['price'], axis=1)\n\n    return X, y, X_sub\n\n\n# Получаем самые частые слова из токенов\ndef get_most_common_words(text, limit=10):   \n    most_common_list = []\n    frequencies = Counter(word for sentence in text for word in sentence)\n    for word, frequency in frequencies.most_common(limit):  # get the 10 most frequent words\n        most_common_list.append(word)\n        \n    return most_common_list\n\n\ndef plot_feature_by_avg_target(df, feature, target='price', title='Средняя цена (Руб.)', plot=True):\n    df_avg_grp = df[[feature, target]].groupby(feature, as_index = False).mean().rename(columns={target:feature+'_avg_'+target})\n    \n    if plot:\n        plt1 = df_avg_grp.plot(x = feature, kind='bar', legend = False, sort_columns = True, figsize = (15,3))\n        plt1.set_xlabel(feature)\n        plt1.set_ylabel(title)\n        plt.xticks(rotation = 90)\n        plt.show()\n    \n    return df_avg_grp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = load_data()\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n\ndf_train, df_test = data_split(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_column', 0)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Удалим из трейна пустые колонки - currency, Комплектация, image, car_url и две пустые записи."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сразу удалим пару пустых записей\ndf_train = df_train[~df_train.bodyType.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С остальными пропусками поработаем позднее. Удалим бесполезные для модели признаки из теста: image, car_url"},{"metadata":{},"cell_type":"markdown","source":"![](https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/04/09140845/shutterstock_352982963.jpg)\n# EDA"},{"metadata":{},"cell_type":"markdown","source":"## bodyType - тип кузова автомобиля"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'bodyType')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что данные очень похожи. Видно что к признаку добавлено количество дверей, но у нас есть отдельный признак **numberOfDoors**, поэтому оставим в признаке только тип кузова.              "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['bodyType'] = df_train.bodyType.apply(lambda x: x.split()[0])\ndf_test['bodyType'] = df_test.bodyType.apply(lambda x: x.split()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'bodyType')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим какие значения пересекаются в выборках\nget_intersection_df(df_train, df_test, 'bodyType')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим какие значения не пересекаются\nget_intersection_df(df_train, df_test, 'bodyType', reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Остался один тип кузова, которого нет в обеих выборках. Можно смело удалять - всего 4 записи."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = merge_dataset(df_train, df_test)\ndf_train.groupby('bodyType').size().plot(kind='pie', textprops={'fontsize': 10})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxplots(data, 'bodyType', 'price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно что, присутствуют выбросы почти в каждой категории."},{"metadata":{},"cell_type":"markdown","source":"## brand - марка авто"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'brand', show_report=True, limit=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В тестовой выборке присутствует 121 брэнд автомобилей, в то время как в тестовой выборке всего 12 моделей. Кроме того видим, что большой объем данных (более 8000 объявлений) составляет Mercedes-Benz. В тестовой выборке он обозначен как MERCEDES, поэтому необходимо переименовать значение в трейне."},{"metadata":{"trusted":true},"cell_type":"code","source":"mercedes = {'MERCEDES-BENZ':'MERCEDES'}\ndf_train.brand = df_train.brand.replace(mercedes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'brand', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С удалением лишних марок поиграемся на этапе валидации моделей."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(20, 5))\nplt.xticks(rotation=90)\nsns.countplot(data=data.groupby(\"brand\").filter(lambda x: len(x) < 1000), x='brand', ax=axes[0])\n\n# Посмотрим на оставшиеся марки\nsns.countplot(data=data.groupby(\"brand\").filter(lambda x: len(x) >= 1000), x='brand')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## color - цвет авто"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'color', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что в тренировочной выборке значения представлены в HEX, а в тестовой словами. Необходимо обработать данный признак. Для этого составим словарь соответствия HEX-->COLOR."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = {\n    'EE1D19': 'красный',\n    'FFD600': 'жёлтый',\n    'DEA522': 'золотистый',\n    'FAFBFB': 'белый',\n    'CACECB': 'серебристый',\n    '040001': 'чёрный',\n    '0000CC': 'синий',\n    '97948F': 'серый',\n    '200204': 'коричневый',\n    '007F00': 'зелёный',\n    '660099': 'пурпурный',\n    'FF8649': 'оранжевый',\n    '22A0F8': 'голубой',\n    'C49648': 'бежевый',\n    '4A2197': 'фиолетовый',\n    'FFC0CB': 'розовый',\n    '40001': 'чёрный'\n}\n\ndf_train.color = df_train.color.replace(colors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'color', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Цвета привели в полное соответствие. это наш категориальный признак."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = merge_dataset(df_train, df_test)\nplot_boxplots(data, 'color', 'price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## complectation_dict - словарь компектаций"},{"metadata":{},"cell_type":"markdown","source":"Данный признак содержит JSON с различной информацией о комплектации автомобиля. В данном признаке очень много пустой информации и для дальнейшей работы он нам не пригодится. Просто отмечаем на удаление."},{"metadata":{},"cell_type":"markdown","source":"## description - описание объявления"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим одну запись\n#df_train.description.value_counts()[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Данный признак содержит описание объявления. Возможно будем использовать как признак для дальнейшей работой с NLP. Оставим пока как есть."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = merge_dataset(df_train, df_test)\ndata.description = data.description.fillna('nodata')\n#data.description = data.description.apply(wrap_nlp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Очистим текст от лишних символов и переносов строк\n# from bs4 import BeautifulSoup\n# import re\n\n# def clear_text(text):\n#     text = text.replace('\\n', ' ')\n#     text = text.replace('\\r', ' ')\n\n#     # Отсекаем лишнее\n#     result = re.sub('[\\W_]+', ' ', text)\n\n#     # Фильтруем совсем маленькое описание - скорее всего мусор\n#     if len(result) < 5:\n#         result = 'nodata'\n\n#     return BeautifulSoup(result.strip(),\"lxml\").get_text()\n\n# data.description = data.description.apply(clear_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Лемматизация описания авто\nИспользование mystem влоб заняло бы на моем компьтере 16 часов. Поэтому пришлось поискать решение в инете. \n\nПомогла статья https://habr.com/ru/post/503420/\n\nПроцесс занимает порядка 10 минут, поэтому сохраняем результат в файл и загружаем в датасет, чтобы не терять время на обработку"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Выполним лемматизацию описания\n# from pymystem3 import Mystem\n# from tqdm import tqdm\n\n# from joblib import Parallel, delayed\n# from nltk.corpus import stopwords\n# from pymystem3 import Mystem\n# from string import punctuation\n\n# batch_size = 1000\n\n# # Объединяем все наши описания в единый список\n# texts = data.description.str.cat(sep='|').split('|')[:]\n\n# # Фильтруем стоп-слова\n# russian_stopwords = stopwords.words(\"russian\")\n\n# text_batch = [texts[i: i + batch_size] for i in range(0, len(texts), batch_size)]\n\n# def lemmatize(text):\n\n#     m = Mystem()\n#     merged_text = \"|\".join(text)\n\n#     doc = []\n#     res = []\n\n#     tokens = m.lemmatize(merged_text)\n#     tokens = [token for token in tokens if token not in russian_stopwords \\\n#                                              and token != \" \"\n#                                              and token != '\\n']\n\n#     for t in tokens:\n#         if t.strip() != '|':\n#             doc.append(t)\n#         else:\n#             res.append(doc)\n#             doc = []\n#     else:\n#         res.append([t])\n    \n#     print(f'Input text len: {len(text)}')\n#     print(f'Output text len: {len(res)}')\n\n#     return res\n\n# Вот здесь тоже немного магии :)\n#processed_texts = Parallel(n_jobs=-1)(delayed(lemmatize)(t) for t in tqdm(text_batch))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def list_to_csv(data=None, filename='data'):\n\n#     if data is not None and isinstance(data, list):\n#         import csv\n\n#         with open(filename+'.csv', 'w+', encoding='utf8', newline ='') as file:\n#             with file:     \n#                 write = csv.writer(file) \n#                 write.writerows(data) \n\n# texts = []\n\n# for batch in tqdm(processed_texts):\n#     for text in batch:\n#         texts.append(text)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\n# Загрузим подготовенный csv с описанием\ndescription = pd.read_csv(DIR_TRAIN+'description.csv', header=None, sep='\\n')\ndata.description = description[0].apply(lambda s: s.split(','))\ndata.description = data.description.fillna('nodata') # 2 записи с NaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Самые частые слова\n# top_desc_words = get_most_common_words(data.description, 1000)\n\n# # Отфильтруем описание по самым частым словам\n# data.description = data.description.apply(lambda s: set([x for x in s if x in top_desc_words]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим признаки из description\n#desc_bins = get_binary_dummies(data, 'description')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вернем обратно train, test\ndf_train, df_test = data_split(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## engineDisplacement - объем двигателя"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'engineDisplacement', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что в тестовой выборке к значениям добавлено LTR, а в тренировочной обозначение дизеля. Приведем признак к одинаковому виду."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отсчем LTR и d\ndf_test.engineDisplacement = df_test.engineDisplacement.apply(lambda x: x.split()[0])\ndf_train.engineDisplacement = df_train.engineDisplacement.apply(lambda x: x.rstrip('d'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'engineDisplacement', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что в тренировочной выборке больше уникальных значений объема двигателя. Вероятно лишние значения мы отсечем в будущем, а пока добавим признак как числовой (чем больше объем, тем дороже автомобиль). Однако, в признаке присутствуют строковые значения Electro и LTR и это нужно обработать. Чтобы особо не мучаться, добавим новый бинарный признак is_electro_car, а объем оставим 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['is_electro_car'] = ((df_train.engineDisplacement == 'Electro') | (df_train.engineDisplacement == 'LTR')).astype('int')\ndf_test['is_electro_car'] = (df_test.engineDisplacement == 'LTR').astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменим значения LTR и Electrocar на 0\ndf_train.engineDisplacement = df_train.engineDisplacement.replace({'Electro': 0})\ndf_test.engineDisplacement = df_test.engineDisplacement.replace({'LTR': 0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Приведем в числовой вид\ndf_train.engineDisplacement = df_train.engineDisplacement.astype('float64')\ndf_test.engineDisplacement = df_test.engineDisplacement.astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение признака\nplot_dist_log(df_train, 'engineDisplacement', figsize=FIGSIZE)\nplot_dist_log(df_test, 'engineDisplacement', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Распределение логнормальное. Добавим новый признак в датасет."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим новый логарифмированный признак\ndf_train['engineDisplacement_log'] = df_train['engineDisplacement'].apply(lambda x: np.log(x+1))\ndf_test['engineDisplacement_log'] = df_test['engineDisplacement'].apply(lambda x: np.log(x+1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## enginePower"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'enginePower', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Опять наши значения не пересекаются в двух выборках. Нужно это поправить. Удалим из тестовой выборки текст **N12**."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.enginePower = df_test.enginePower.apply(lambda x: x.rstrip('N12'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'enginePower', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Приведем в числовой вид\ndf_train.enginePower = df_train.enginePower.astype('int64')\ndf_test.enginePower = df_test.enginePower.astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение признака\nplot_dist_log(df_train, 'enginePower', figsize=FIGSIZE)\nplot_dist_log(df_test, 'enginePower', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим новый логарифмированный признак\ndf_train['enginePower_log'] = np.log(df_train.enginePower + 1)\ndf_test['enginePower_log'] = np.log(df_test.enginePower + 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## equipmentDict - словарь с опциями"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.equipment_dict.value_counts().nlargest(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что словарь содержит достаточно много пропусков - **24437**. Можно попробовать вытащить из описания какие-то признаки, а из словаря сделать дамми-переменные. На данном этапе оставим как есть. Поработаем с данными признаками после EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на список уникальных опций\ndata = merge_dataset(df_train, df_test)\ndata.equipment_dict = data.equipment_dict.fillna('{\"nan\": True}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получим уникальные значения опций и проверим предположение, что значение ключа опций содержит только True, т.е. нам нужны только ключи словаря"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_options = data.equipment_dict.to_dict()\nunique_vals = set()\nimport ast\n\nfalse_count = 0\nfor item in unique_options.values():\n    item = item.replace('true', \"True\")\n    opt = ast.literal_eval(item)\n    for key, value in opt.items():\n        # Убедимся, что оптиции не содержат False\n        if value == False:\n            false_count += 1\n        unique_vals.add(key)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Оценим количество опций"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество опций из которых сделаем дамми переменные\nprint(f'Уникальных опций: {len(unique_vals)}')\nprint(unique_vals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что много непонятных опций. Попробуем отфильтровать лишние и оставить наиболее понятные."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nregex = r\"([0-9A-Z]){3,}\\b\"\ntest_str = ' '.join(unique_vals)\nreplaced_str = re.sub(regex, '', test_str, 0, re.MULTILINE)\nfiltered_options = replaced_str.split()\n\nlen(filtered_options)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Приведем опции к виду словаря\ndata.equipment_dict = data.equipment_dict.apply(lambda s: s.replace('true', 'True'))\ndata.equipment_dict = data.equipment_dict.map(ast.literal_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Приведем словарь к списку опций\ndata.equipment_dict = data.equipment_dict.apply(lambda s: [option for option, value in s.items() if option in filtered_options])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на самые популярные опции\nfrom collections import Counter\n\ncounter = Counter()\ndata.equipment_dict.apply(lambda x: counter.update(x))\n\ncounter.most_common(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## fuelType - вид топлива"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'fuelType', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тут все просто - создаем словарь соответствия и заменям значения в трейне."},{"metadata":{"trusted":true},"cell_type":"code","source":"gasoline = {\n    'GASOLINE': 'бензин',\n    'DIESEL': 'дизель',\n    'HYBRID': 'гибрид',\n    'ELECTRO': 'электро',\n    'LPG': 'газ'\n}\n\ndf_train.fuelType = df_train.fuelType.replace(gasoline)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'fuelType', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На данном этапе работу с признаком закончили."},{"metadata":{},"cell_type":"markdown","source":"## mileage - пробег"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'mileage', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df_train, 'mileage', figsize=FIGSIZE)\nplot_dist_log(df_test, 'mileage', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим распределение с правым хвостом, при этом имеются выбросы в нулевой зоне (в выборке есть новые автомобили). Выбросы будем обрабатывать позже."},{"metadata":{},"cell_type":"markdown","source":"## modelDate - год выпуска модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'modelDate', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df_train, 'modelDate', figsize=FIGSIZE)\nplot_dist_log(df_test, 'modelDate', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что хвост смещен влево, так как в данных присутствуют раритеные автомобили. Оставим на этап работы с выбросами. Сразу создадим признак **modelAge** - сколько модели лет."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['modelAge'] = CURRENT_YEAR - df_train['modelDate']\ndf_test['modelAge'] = CURRENT_YEAR - df_test['modelDate']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## model_info - сборный признак информации по модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'model_info', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ничего интересного - просто словарь некоторых параметров, которые у нас и так есть. **ВЫВОД:** в утиль."},{"metadata":{"trusted":true},"cell_type":"code","source":"## model_name - название модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'model_name', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Много уникальных значений в тренировочной выборке, т.к. в тестовой всего 12 брэндов. Почти полное пересечение с тренировочной выборкой. Оставим признак как категориальный."},{"metadata":{},"cell_type":"markdown","source":"## name - сборное название модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'name', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Составной признак - содержит информацию, которая у нас есть в других колонках (объем двигателя, коробка передач и мощность двигателя). Посмотрим как поведет себя на обучении."},{"metadata":{},"cell_type":"markdown","source":"## numberOfDoors - количество дверей"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'numberOfDoors', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Впринципе тут всё предсказуемо. Однако машины с 0 дверьми - это весьма интересно :) Давайте это поправим."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train.numberOfDoors == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что это редкие гоночные болиды и вездеходы. Для нашей выборки это выбросы. С ними разберемся отдельно."},{"metadata":{},"cell_type":"markdown","source":"## productionDate - год выпуска автомобиля"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'productionDate', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что по году выпуска все ровно - не пересекается всего 4 года. Посмотрим на распределение признака."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df_train, 'productionDate', figsize=FIGSIZE)\nplot_dist_log(df_test, 'productionDate', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что признак очень похож на modelDate и вероятнее всего у них будет высокая корреляция. Это мы проверим, когда будем строить heatmap."},{"metadata":{},"cell_type":"markdown","source":"# sell_id, super_gen"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'sell_id', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**sell_id** - Просто инсайтище в данных :) Видно, что это уникальный идентификатор объявления на auto.ru и мы можем по нему определить 19367 объявлений по трейну, но по правилам соревнования это запрещено, поэтому признак в будущем удалим."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.super_gen.value_counts().nlargest(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**super_gen** - содержит словарь с технической информацией автомобиля. При беглом осмотре видим, что из него можно достать новые признаки - ускорение до 100км/ч, расход топлива и дорожный просвет. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переведем в словарь\ndata = merge_dataset(df_train, df_test)\n#data.super_gen = data.super_gen.map(ast.literal_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вытащим новые признаки из super_gen\ndef super_gen_extract_feature(s, feature):\n    if feature in s.keys():\n        return s[feature]\n    else:\n        return np.nan\n\n# Фичи из super-gen\ndata['acceleration'] = data['super_gen'].apply(super_gen_extract_feature, args=('acceleration',))\ndata['clearance_min'] = data['super_gen'].apply(super_gen_extract_feature, args=('clearance_min',))\ndata['fuel_rate'] = data['super_gen'].apply(super_gen_extract_feature, args=('fuel_rate',))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим сколько пропусков\nprint('Acceleration: ', data.acceleration.isnull().sum())\nprint('Clearence', data.clearance_min.isnull().sum())\nprint('FuelRate', data.fuel_rate.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть достаточно пропусков, но заполнить их по другим данным не проблема."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Заполним средним по типу кузова\n# display(data.groupby('bodyType')['acceleration'].mean().round(1))\n\n# # Есть пропуски, нужно их заполнить тоже :) Посмотрим среднее ускорение по объему двигателя\n# display(data[data.bodyType.isin(['седан-хардтоп', 'фастбек'])].enginePower.mean())\n\n# ep_grp = data.groupby('enginePower').acceleration.mean()\n# ep_grp[(ep_grp.index > 130) & (ep_grp.index < 135)]\n\n# # Создаем словарь, а наши пропуски по кузову заполняем средним в 12 секунд\n# mean_acceleration = data.groupby('bodyType')['acceleration'].mean().round(1).to_dict()\n\n# print(mean_acceleration)\n\ndef fill_super_gen(s, feature):\n    assert (feature in ['acceleration', 'fuel_rate', 'clearance_min'])\n    \n    replaces = {\n        'acceleration': {'внедорожник': 9.9, 'кабриолет': 7.6, 'компактвэн': 13.0, 'купе': 6.7, 'купе-хардтоп': 7.2,\n                             'лимузин': 7.5, 'лифтбек': 10.1, 'микровэн': 18.0, 'минивэн': 12.8,\n                             'пикап': 13.5, 'родстер': 6.7, 'седан': 10.2, 'седан-хардтоп': 12,\n                             'спидстер': 2.4, 'тарга': 8.6, 'универсал': 11.4, 'фастбек': 12,\n                             'фургон': 18.4, 'хэтчбек': 12.0},\n\n        'fuel_rate': {'внедорожник': 9.0, 'кабриолет': 9.4, 'компактвэн': 7.2, 'купе': 8.9, 'купе-хардтоп': 8.9,\n                         'лимузин': 14.9, 'лифтбек': 6.7, 'микровэн': 5.6, 'минивэн': 8.4, 'пикап': 9.1, 'родстер': 9.8,\n                         'седан': 7.7, 'седан-хардтоп': 9.3, 'спидстер': 7.6, 'тарга': 9.6, 'универсал': 7.7, 'фастбек': 9.5,\n                         'фургон': 8.6, 'хэтчбек': 6.8},\n\n        'clearance_min': {'внедорожник': 203.0, 'кабриолет': 135.0, 'компактвэн': 151.0, 'купе': 131.0, 'купе-хардтоп': 153.0,\n                          'лимузин': 154.0, 'лифтбек': 155.0, 'микровэн': 160.0, 'минивэн': 168.0, 'пикап': 216.0, 'родстер': 134.0,\n                          'седан': 151.0, 'седан-хардтоп': 151.0, 'спидстер': 50, 'тарга': 129.0, 'универсал': 154.0,\n                          'фастбек': 135.0, 'фургон': 157.0, 'хэтчбек': 151.0}\n    }\n    \n    return replaces[feature][s]\n\ndata['acceleration'] = data.apply(lambda row: fill_super_gen(row.bodyType, 'acceleration') if pd.isnull(row.acceleration) else row.acceleration, axis=1)\ndata['clearance_min'] = data.apply(lambda row: fill_super_gen(row.bodyType, 'clearance_min') if pd.isnull(row.clearance_min) else row.clearance_min, axis=1)\ndata['fuel_rate'] = data.apply(lambda row: fill_super_gen(row.bodyType, 'fuel_rate') if pd.isnull(row.fuel_rate) else row.fuel_rate, axis=1)\n\n\n\nprint('Acceleration: ', data.acceleration.isnull().sum())\nprint('Clearence', data.clearance_min.isnull().sum())\nprint('FuelRate', data.fuel_rate.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## vehicleConfiguration - конфигурация авто"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = data_split(data)\ndf_train.vehicleConfiguration.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак является составным из bodyType, vehicleTransmission и engineDisplacement. Смело удаляем его."},{"metadata":{},"cell_type":"markdown","source":"## vehicleTransmission - коробка передач"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'vehicleTransmission', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полное соответствие признака - просто приведем его к единому виду."},{"metadata":{"trusted":true},"cell_type":"code","source":"transmission = {\n    'AUTOMATIC': 'автоматическая',\n    'MECHANICAL': 'механическая',\n    'ROBOT': 'вариатор',\n    'VARIATOR': 'роботизированная'\n}\n\ndf_train.vehicleTransmission = df_train.vehicleTransmission.replace(transmission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## vendor - тип производитея авто"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'vendor', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что в тестовой выборке присутствуют только японские и европейские марки, поэтому посмотрим, что лучше сработает - удаление лишних или их группировка в отдельную категорию - OTHER."},{"metadata":{},"cell_type":"markdown","source":"## Владельцы"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Владельцы', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В тренировочной выборке присутствуют пропуски. Посмотрим на их количество. Предполагаю, что это новые автомобили."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Владельцы'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на значения пробега\ndf_train[df_train['Владельцы'].isnull()].mileage.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как мы и предполагали - это объявления о продаже новых автомобилей. Выделим их в отдельную - 0, а там посмотрим на этапе работы с выбросами."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Приведем признак в соответствие\nowners = {\n    1.0: '1 владелец',\n    2.0: '2 владельца',\n    3.0: '3 или более'\n\n}\n\ndf_train['Владельцы'] = df_train['Владельцы'].replace(owners)\ndf_train['Владельцы'] = df_train['Владельцы'].fillna('новый авто')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Владельцы', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Наши четыре категории приведены к единому виду. "},{"metadata":{},"cell_type":"markdown","source":"## Владение"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Владение', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Помним при беглом осмотре данных, что признак содержит очень много пропусков. Убедимся в этом еще раз."},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_checks(df_train)\neda_checks(df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"72% пропусков на трейне и 65% на тесте. Однозначно удаляем признак."},{"metadata":{},"cell_type":"markdown","source":"## ПТС"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'ПТС', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак содержит два значения и пропуски. Во-первых, приведем признак к единому виду, а во вторых заполним пропуски как Дубликат."},{"metadata":{"trusted":true},"cell_type":"code","source":"pts = {\n    True: 'Оригинал',\n    np.nan: 'Дубликат'\n}\n\ndf_train['ПТС'] = df_train['ПТС'].replace(pts)\ndf_test['ПТС'] = df_test['ПТС'].replace(pts)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'ПТС', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Привод"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Привод', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Категориальный признак на 3 категории. Просто приведем к единому виду."},{"metadata":{"trusted":true},"cell_type":"code","source":"gear_type = {\n    'FORWARD_CONTROL': 'передний',\n    'ALL_WHEEL_DRIVE': 'полный',\n    'REAR_DRIVE': 'задний'\n}\n\ndf_train['Привод'] = df_train['Привод'].replace(gear_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Привод', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Руль"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Руль', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тут все просто - приводим к единому виду."},{"metadata":{"trusted":true},"cell_type":"code","source":"wheel_drive = {\n    'LEFT': 'Левый',\n    'RIGHT': 'Правый'\n}\n\ndf_train['Руль'] = df_train['Руль'].replace(wheel_drive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Руль', show_report=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Состояние"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Состояние', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Бесполезный признак с 1 значением - на удаление."},{"metadata":{},"cell_type":"markdown","source":"## Таможня"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_features_in_df(df_train, df_test, 'Таможня', show_report=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тоже признак с 1 значением - на удаление."},{"metadata":{},"cell_type":"markdown","source":"## price - цена авто - наш таргет!"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = merge_dataset(df_train, df_test)\n\n# Посмотрим распределение цены по брэндам\ndf_comp_avg_price = plot_feature_by_avg_target(data, 'brand', plot=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разделим авто по категориям по средней цене\ndata = data.merge(df_comp_avg_price, on = 'brand')\ndata['brand_category'] = data['brand_avg_price'].apply(lambda x : \"Budget\" if x < 0.1e7 \n                                                     else (\"Mid_Range\" if 0.1e7 <= x < 0.3e7\n                                                           else \"Luxury\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# По типу топлива\ndf_fuel_avg_price = plot_feature_by_avg_target(data, 'fuelType')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Электрокары в выборке самые дорогие."},{"metadata":{"trusted":true},"cell_type":"code","source":"# По типу корпуса\ndf_bodyType_avg_price = plot_feature_by_avg_target(data, 'bodyType')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Самая высокая цена у лимузинов, спидстеров и тарга"},{"metadata":{"trusted":true},"cell_type":"code","source":"# По дверям\ndf_doors_avg_price = plot_feature_by_avg_target(data, 'numberOfDoors')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Самые дорогие авто без дверей - спидстеры, что логично"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_geartype_avg_price = plot_feature_by_avg_target(data, 'Привод')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist_log(df_train, 'price', figsize=FIGSIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что распределение логнормальное. Посмотрим на распределение с другими признаками."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['price_log'] = df_train.price.map(np.log1p)\ncols = ['engineDisplacement', 'enginePower', 'mileage', 'modelAge', 'modelDate', 'productionDate']\nsns.pairplot(df_train, x_vars=cols, y_vars=['price_log'], kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_checks(df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть пропуски в таргете. Просто удалим эти записи."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train[~df_train.price.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Визуализация Price с числовыми признаками"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = merge_dataset(df_train, df_test)\nnum_cols = data.select_dtypes(include=['int64', 'float64']).columns\n\nprint(num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"engineDisplacement\", y=\"price_log\", data=data,color='purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"enginePower\", y=\"price_log\", data=data,color='purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"mileage\", y=\"price_log\", data=data,color='purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"modelDate\", y=\"price_log\", data=data,color='purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Корреляция"},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap_numeric_target_variable(data, 'price_log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_correlation(data.select_dtypes(include=['int64', 'float64']).corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, больше всего взаимосвязь таргета с мощностью двигателя, датой производства и выпуска модели, объемом двигателя и пробегом автомобиля. Между собой высокая корреляция у enginePower и engineDisplacement и modelDate и productionDate. Однозначно признаки Date нужно будет удалять после преобразования в новые."},{"metadata":{},"cell_type":"markdown","source":"## Значимость признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ANOVA\nplot_fclassif(df_train, cols, 'price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MUTUAL\n\n# Удалим лишние признаки\ndf_ = df_train.drop(['super_gen', 'equipment_dict', 'model_info', 'complectation_dict', 'car_url', 'description', 'image', 'Владение'], axis=1)\n\n# Отберем только категориальные\ndf_ = df_.select_dtypes(include=['object'])\n\n# Нужно закодировать признаки для функции mutual_info_classif\nle = OrdinalEncoder()\ndf_encoded_values = le.fit_transform(df_)\n\n# Признаки для теста\ntest_cols = list(df_.columns)\n\n# np.array закодированных признаков и таргета\ndf_encoded_values = np.c_[df_encoded_values, df_train.price.values.reshape(-1, 1)]\n\n# Заворачиваем в датафрэйм\ndf_encoded = pd.DataFrame(df_encoded_values, columns=test_cols + ['price'])\n\n# Смотрим статистически значимые признаки\nplot_mutual_info_classif(df_encoded, df_.columns, 'price')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA ВЫВОДЫ:**\n- {C} **bodyType**: Привели признак в соответствие выборок. Определили как категориальный.    \n\n- {C} **brand**: В тестовой выборке 12 марок автомобилей, в обучаюшей 121. Привели марку Mercedes в единый формат между выборками. С группировкой или удалением данных поиграемся на этапе ML. Определили как категориальный.  \n\n- ~~**car_url**~~ - ссылка на объявление. Удаляем признак. \n\n- {C} **color** - цвет автомобилей привели в соответствие. Определили как категориальный.\n\n- ~~**complectation_dict**~~ - много пропусков. Удаляем признак.\n\n- **description** - на этапе feauture engineering, возможно достанем полезную информацию.\n\n- {N} **engineDisplacement** - Привели признак в соответствие выборок. Автомобили с электродвигателем отметили как имеющие объем 0 и дополнительно введем признак is_electro_car на этапе FE. Определили как числовой.\n\n- {N} **enginePower** - Привели в соответствие. Определили как числовой.         \n\n- **equipment_dict** - Из признака можно достать много dummy-переменных. Оставили на этап FE.\n      \n- {C} **fuelType** - Привели в соответствие выборок. Определили как категориальный.\n\n- ~~**image**~~ - ссылки на фото. Удаляем.       \n\n- {N} **mileage** - Пробег автомобиля имеет выбросы в точке 0 (новые авто). Определили как числовой.\n\n- {N} **modelDate** - Дата производства марки. Коррелирует с датой производства автомобиля. Числовой.   \n\n- ~~**model_info**~~ - Не содержит полезной информации. Удаляем.       \n\n- {C} **model_name** - Модель авто. Категориальный.  \n\n- {C} **name** - Составной признак. Посмотрим как поведет себя при обучении. Возможно удалим.   \n\n- {C} **numberOfDoors** - Привели в соответствие выборок. Категориальный.      \n\n- ~~**parsing_unixtime**~~ - время парсинга. Удаляем.   \n\n- ~~**priceCurrency**~~ - валюта. Удаляем.   \n\n- {N} **productionDate** - Дата выпуска модели. Создадим новый признак на этапе FE.    \n\n- ~~**sell_id**~~ - ИНСАЙТ! ID объявления с авто.ру. Удаляем в соответствие с правилами.\n\n- **super_gen** - содержит словарь с технической информацией автомобиля. При беглом осмотре видим, что из него можно достать новые признаки - ускорение до 100км/ч, расход топлива и дорожный просвет.       \n\n- {C} **vehicleConfiguration** - Составной признак. Посмотрим как поведет себя.\n\n- {C} **vehicleTransmission** - привели в соответствие выборок. Категориальный. \n\n- {C} **vendor** - В тестовой выборке присутствуют только японские и европейские марки, поэтому посмотрим, что лучше сработает - удаление лишних или их группировка в отдельную категорию - OTHER. Категориальный. \n\n- {C} **Владельцы** - привели в соответствие выборок. Пропуски определили как новый автомобиль. Категориальный. \n\n- ~~**Владение**~~ - Много пропусков в данных. Удаляем.       \n\n- {C} **ПТС** - Определили пропуски как дупикат ПТС. Категориальный.    \n\n- {C} **Привод** - Привели в соответствие выборок. Категориальный.  \n\n- {C}{B} **Руль** - привелив соответствие. Бинарный или категориальный.   \n             \n- ~~**Состояние**~~ - Одно значение. Удаляем.   \n\n- ~~**Таможня**~~ - Одно значение. Удаляем.    \n         \n- {T} **price** - Наш таргет. Наибольшая связь с мощностью двигателя, датой производства и выпуска модели, объемом двигателя и пробегом автомобиля.    \n\nПодводя итоги, у нас получается для работы есть 14 категориальных признаков, 5 сисловых, 3 для создания новых признаков.  "},{"metadata":{},"cell_type":"markdown","source":"![Очистка данных](https://ua.all.biz/img/ua/service_catalog/432798.jpeg)\n# Data Preprocessing\n### На данном этапе завернем всё, что мы обнаружили в рамках EDA при помощи SKlearn API для использования в пайплайне"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Напишем наши классы обработки данных\nclass DatasetProcessing(BaseEstimator, TransformerMixin):\n    def __init__(self, use_log=False, cat_boost_prepare=False, filter_data=False, target_encode=False):\n        self.use_log=use_log\n        self.cat_boost_prepare = cat_boost_prepare\n        self.filter_data = filter_data\n        self.target_encode = target_encode\n        \n        self.test_brands = ['BMW',           \n                            'VOLKSWAGEN',   \n                            'NISSAN', \n                            'MERCEDES',     \n                            'TOYOTA',       \n                            'AUDI',         \n                            'MITSUBISHI',   \n                            'SKODA',        \n                            'VOLVO',        \n                            'HONDA',        \n                            'INFINITI',     \n                            'LEXUS'\n                           ]\n        \n        # Наши словари замен\n        self.dicts = {\n            'brand': {'MERCEDES-BENZ':'MERCEDES'},\n            'color':  {\n                        'EE1D19': 'красный',\n                        'FFD600': 'жёлтый',\n                        'DEA522': 'золотистый',\n                        'FAFBFB': 'белый',\n                        'CACECB': 'серебристый',\n                        '040001': 'чёрный',\n                        '0000CC': 'синий',\n                        '97948F': 'серый',\n                        '200204': 'коричневый',\n                        '007F00': 'зелёный',\n                        '660099': 'пурпурный',\n                        'FF8649': 'оранжевый',\n                        '22A0F8': 'голубой',\n                        'C49648': 'бежевый',\n                        '4A2197': 'фиолетовый',\n                        'FFC0CB': 'розовый',\n                        '40001': 'чёрный'\n                    },\n             'engineDisplacement': {\n                        'LTR': 0,\n                        'Electro': 0,\n             },\n\n             'fuelType': {\n                        'GASOLINE': 'бензин',\n                        'DIESEL': 'дизель',\n                        'HYBRID': 'гибрид',\n                        'ELECTRO': 'электро',\n                        'LPG': 'газ'\n            },\n            'transmission': {\n                        'AUTOMATIC': 'автоматическая',\n                        'MECHANICAL': 'механическая',\n                        'ROBOT': 'вариатор',\n                        'VARIATOR': 'роботизированная'\n            },\n            'owners':  {\n                        1.0: '1 владелец',\n                        2.0: '2 владельца',\n                        3.0: '3 или более'\n\n            },\n            'pts': {\n                        True: 'Оригинал',\n                        np.nan: 'Дубликат'\n            },\n            'gear_type': {\n                        'FORWARD_CONTROL': 'передний',\n                        'ALL_WHEEL_DRIVE': 'полный',\n                        'REAR_DRIVE': 'задний'\n            },\n            'wheel_drive': {\n                        'LEFT': 'Левый',\n                        'RIGHT': 'Правый'\n            }\n\n\n        }\n\n    def get_dicts(self, feature):\n        pass\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        X_ = X.copy() # работаем с копией\n        \n        # Группируем данные по брэнду        \n        if self.filter_data:\n            brands = list(X_[~X_.brand.isin(self.test_brands)].brand.value_counts().index)\n            X_.brand = X_.brand.apply(lambda x: 'OTHER' if x in brands else x)\n\n        # bodyType\n        X_.dropna(subset=['bodyType'], inplace=True)\n        X_['bodyType'] = X_['bodyType'].apply(lambda x: x.split()[0])\n        \n        # brand\n        X_.brand = X_.brand.replace(self.dicts['brand'])\n\n        # color\n        X_.color = X_.color.replace(self.dicts['color'])\n\n        # engineDisplacement\n        X_.engineDisplacement = X_.engineDisplacement.apply(lambda x: x.split()[0])\n        X_.engineDisplacement = X_.engineDisplacement.apply(lambda x: x.rstrip('d'))\n        X_['is_electro_car'] = ((X_.engineDisplacement == 'Electro') | (X_.engineDisplacement == 'LTR')).astype('int')\n        X_.engineDisplacement = X_.engineDisplacement.replace(self.dicts['engineDisplacement'])\n        X_.engineDisplacement = X_.engineDisplacement.astype('float64')\n\n        # enginePower\n        X_.enginePower = X_.enginePower.astype('str')\n        X_.enginePower = X_.enginePower.apply(lambda x: x.rstrip('N12'))\n        X_.enginePower = X_.enginePower.astype('float64')\n\n        # FuelType\n        X_.fuelType = X_.fuelType.replace(self.dicts['fuelType'])\n\n        # vehicleTransmission\n        X_.vehicleTransmission = X_.vehicleTransmission.replace(self.dicts['transmission'])\n\n        # Владельцы\n        X_['Владельцы'] = X_['Владельцы'].replace(self.dicts['owners'])\n        X_['Владельцы'] = X_['Владельцы'].fillna('новый авто')\n\n        # ПТС\n        X_['ПТС'] = X_['ПТС'].replace(self.dicts['pts'])\n\n        # Привод\n        X_['Привод'] = X_['Привод'].replace(self.dicts['gear_type'])\n\n        # Руль\n        X_['Руль'] = X_['Руль'].replace(self.dicts['wheel_drive'])\n\n        # Desription\n        X_.description = X_.description.fillna('[]')\n\n        # Пропуски в Price\n        if 'price' in X_.columns:\n            X_test = X_[X_['sample'] == 0]\n            X_train = X_[X_['sample'] == 1]\n            X_train = X_train[~X_train.price.isnull()]\n            X_ = X_test.append(X_train, sort=False).reset_index(drop=True) # объединяем\n\n\n        # Пропуски в equipment_dict\n        X_.equipment_dict = X_.equipment_dict.fillna('{}')\n        \n#         # Brand\n#         df_comp_avg_price = plot_feature_by_avg_target(X_, 'brand', plot=False)\n#         X_ = X_.merge(df_comp_avg_price, on = 'brand')\n#         X_['brand_category'] = X_['brand_avg_price'].apply(lambda x : \"Budget\" if x < 0.1e7 \n#                                                      else (\"Mid_Range\" if 0.1e7 <= x < 0.3e7\n#                                                            else \"Luxury\"))\n\n                # superGen\n        # Вытащим новые признаки из super_gen\n        def super_gen_extract_feature(s, feature):\n            if feature in s.keys():\n                return s[feature]\n            else:\n                return np.nan\n\n        # Фичи из super-gen\n        X_['acceleration'] = X_['super_gen'].apply(super_gen_extract_feature, args=('acceleration',))\n        X_['clearance_min'] = X_['super_gen'].apply(super_gen_extract_feature, args=('clearance_min',))\n        X_['fuel_rate'] = X_['super_gen'].apply(super_gen_extract_feature, args=('fuel_rate',))\n        \n        # super_gen\n        def fill_super_gen(s, feature):\n            assert (feature in ['acceleration', 'fuel_rate', 'clearance_min'])\n\n            replaces = {\n                'acceleration': {'внедорожник': 9.9, 'кабриолет': 7.6, 'компактвэн': 13.0, 'купе': 6.7, 'купе-хардтоп': 7.2,\n                                     'лимузин': 7.5, 'лифтбек': 10.1, 'микровэн': 18.0, 'минивэн': 12.8,\n                                     'пикап': 13.5, 'родстер': 6.7, 'седан': 10.2, 'седан-хардтоп': 12,\n                                     'спидстер': 2.4, 'тарга': 8.6, 'универсал': 11.4, 'фастбек': 12,\n                                     'фургон': 18.4, 'хэтчбек': 12.0},\n\n                'fuel_rate': {'внедорожник': 9.0, 'кабриолет': 9.4, 'компактвэн': 7.2, 'купе': 8.9, 'купе-хардтоп': 8.9,\n                                 'лимузин': 14.9, 'лифтбек': 6.7, 'микровэн': 5.6, 'минивэн': 8.4, 'пикап': 9.1, 'родстер': 9.8,\n                                 'седан': 7.7, 'седан-хардтоп': 9.3, 'спидстер': 7.6, 'тарга': 9.6, 'универсал': 7.7, 'фастбек': 9.5,\n                                 'фургон': 8.6, 'хэтчбек': 6.8},\n\n                'clearance_min': {'внедорожник': 203.0, 'кабриолет': 135.0, 'компактвэн': 151.0, 'купе': 131.0, 'купе-хардтоп': 153.0,\n                                  'лимузин': 154.0, 'лифтбек': 155.0, 'микровэн': 160.0, 'минивэн': 168.0, 'пикап': 216.0, 'родстер': 134.0,\n                                  'седан': 151.0, 'седан-хардтоп': 151.0, 'спидстер': 50, 'тарга': 129.0, 'универсал': 154.0,\n                                  'фастбек': 135.0, 'фургон': 157.0, 'хэтчбек': 151.0}\n            }\n\n            return replaces[feature][s]\n\n        X_['acceleration'] = X_.apply(lambda row: fill_super_gen(row.bodyType, 'acceleration') if pd.isnull(row.acceleration) else row.acceleration, axis=1)\n        X_['clearance_min'] = X_.apply(lambda row: fill_super_gen(row.bodyType, 'clearance_min') if pd.isnull(row.clearance_min) else row.clearance_min, axis=1)\n        X_['fuel_rate'] = X_.apply(lambda row: fill_super_gen(row.bodyType, 'fuel_rate') if pd.isnull(row.fuel_rate) else row.fuel_rate, axis=1)\n\n        # CatBoost LabelEncoder\n        if self.cat_boost_prepare:\n            for column in X_.select_dtypes(include=['object']).columns:\n                if column not in ['description', 'equipment_dict', 'super_gen']:\n                    X_[column] = X_[column].astype('category').cat.codes\n            \n        # Приведем числовые признаки к единому виду\n        X_['enginePower'] =  X_['enginePower'].astype('int64')\n        X_['modelDate'] =  X_['modelDate'].astype('int64')\n        X_['productionDate'] = X_['productionDate'].astype('int64')\n        X_['numberOfDoors'] = X_['numberOfDoors'].astype('int64')\n\n        # Производим логарифмирование признаков\n        if self.use_log:\n            X_['engineDisplacement_log'] = np.log(X_['engineDisplacement'] + 1)\n            X_['enginePower_log'] = np.log(X_.enginePower + 1)\n            X_['mileage_log'] = np.log1p(X_.mileage)\n            # X_.drop(['engineDisplacement', 'enginePower', 'mileage'], axis=1, inplace=True)\n            \n        # Rename columns\n        columns_rename = {'Владельцы': 'owners', 'Владение': 'ownage', 'ПТС': 'pts', 'Привод': 'gear_type', 'Руль': 'wheeldrive', 'Состояние': 'health', 'Таможня': 'custom'}                \n        X_.rename(columns=columns_rename, inplace=True)\n\n        return X_\n\n# FeatureEngineering\nclass DatasetFE(BaseEstimator, TransformerMixin):\n    def __init__(self, ohe=False, use_equip=False):\n        self.ohe=ohe\n        self.use_equip=use_equip\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        import ast\n        import re         \n          \n        if self.use_equip:\n            # equipmentDict\n            unique_options = X.equipment_dict.to_dict()\n            unique_vals = set()\n            for item in unique_options.values():\n                item = item.replace('true', \"True\")\n                opt = ast.literal_eval(item)\n                for key, value in opt.items():\n                    unique_vals.add(key)\n\n            # Приведем словарь опций в отфильтрованный список\n            X.equipment_dict = X.equipment_dict.fillna('{\"nan\": True}')\n            X.equipment_dict = X.equipment_dict.apply(lambda s: s.replace('true', 'True'))\n            X.equipment_dict = X.equipment_dict.map(ast.literal_eval)\n            X.equipment_dict = X.equipment_dict.apply(lambda s: [key for key, value in s.items() if key in unique_vals])\n            equipmemt_bins = get_binary_dummies(X, 'equipment_dict')\n\n            X = pd.concat([X, equipmemt_bins], axis=1)\n        \n        # model dates\n        X['modelAge'] =  CURRENT_YEAR - X['modelDate']\n        X['carAge'] = CURRENT_YEAR - X['productionDate']\n        X['carAge_to_modelAge'] = X['modelAge'] - X['carAge']\n        \n        # milenage\n        X['mileage_carAge'] = X['carAge'] / (X['mileage'] + 1)\n        X['mileage_modelAge'] = X['modelAge'] / (X['mileage'] + 1)\n        \n        def permile(row):\n            if not row['modelAge']:\n                return row['mileage']\n            else:\n                return round(row['mileage'] / row['modelAge'], 1)\n\n        def cat_mileagePerYear(x):\n            if x < 15000: x = 1\n            elif 15000 <= x < 30000: x = 2\n            elif 30000 <= x < 45000: x = 3\n            elif 45000 <= x: x = 4\n            return x \n        \n        def tax_engine_power(x):\n            if x <= 100: x = 1\n            elif 101 <= x <= 125: x = 2\n            elif 126 <= x <= 150: x = 3\n            elif 156 <= x <= 175: x = 4\n            elif 176 <= x <= 200: x = 5\n            elif 201 <= x <= 225: x = 6\n            elif 226 <= x <= 250: x = 7\n            elif 251 < x: x = 8\n       \n            return x\n       \n        def cat_mileage(x):\n            if x < 25000: x = 1\n            elif 25000 <= x < 50000: x = 2\n            elif 50000 <= x < 75000: x = 3\n            elif 75000 <= x < 100000: x = 4\n            elif 100000 <= x < 125000: x = 5\n            elif 125000 <= x < 150000: x = 6\n            elif 150000 <= x < 175000: x = 7\n            elif 175000 <= x < 200000: x = 8\n            elif 200000 <= x < 225000: x = 9\n            elif 225000 <= x < 250000: x = 10\n            elif 250000 <= x < 275000: x = 11\n            elif 275000 <= x < 300000: x = 12\n            elif 300000 <= x < 325000: x = 13\n            elif 325000 <= x < 350000: x = 14\n            elif 350000 <= x < 375000: x = 15\n            elif 375000 <= x < 400000: x = 16\n            elif 400000 <= x: x = 17\n                \n            return x   \n        \n        X['cat_mileage'] = X['mileage'].apply(cat_mileage)\n        X['tax_engine_power'] = X['enginePower'].apply(tax_engine_power)\n        X['AgePerMile'] = X.apply(permile, axis=1)\n        X['AgePerMile'] = X['AgePerMile'].astype('int64')\n        X['cat_mileagePerYear'] = X['AgePerMile'].apply(lambda x: cat_mileagePerYear(x))\n        \n        # use OneHot\n        if self.ohe:\n            one_hot_cols = ['numberOfDoors', 'pts', 'wheeldrive', 'fuelType']\n            X = pd.get_dummies(X, columns=one_hot_cols)   \n               \n        return X\n\n# Отбираем фичи\nclass FeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, features):\n        self.features = list(features)\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        return X[self.features + ['sample', 'price']]\n    \n\n# Удаляем лишние фичи\nclass FeatureEraser(BaseEstimator, TransformerMixin):\n    def __init__(self, features):\n        assert(type(features) == list)\n        self.features = features\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X, y = None):\n        return X.drop(self.features, axis=1)\n    \n    \n# TargetEncoder\nclass TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, columns=None, target=None, df_type=None, train=None, n_folds=5):\n        self.columns = columns\n        self.target = target\n        self.n_folds = n_folds\n        self.df_type = df_type\n        self.train = train\n    \n    def get_encoded_names(self, column):\n        return column + '_' + 'Kfold_Target_Enc'\n        \n    def fit(self, X):\n        return self\n    \n    def transform(self, X):\n        assert(type(self.columns) == list)\n        assert([col for col in self.columns if col in X.columns])\n        assert(self.df_type in ['train', 'test'])\n        \n        for col in self.columns:\n            if self.df_type == 'train':\n                target_enc = KFoldTargetEncoderTrain(col, self.target, n_fold=self.n_folds)\n                X = target_enc.fit_transform(X)\n            else:\n                assert([col for col in self.columns if col in self.train.columns])\n                target_enc = KFoldTargetEncoderTest(self.train, col, self.get_encoded_names(col))\n                X = target_enc.fit_transform(X)\n            \n        return X\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FEATURE SELECTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndata = load_data()\n\n# Плохие брэнды по результатам работы моделей\nbad_mape_brands = [  'PROTON', 'HUANGHAI', 'TESLA', 'DW HOWER', 'DATSUN', 'FERRARI', 'MASERATI', 'IVECO',\n                     'BAJAJ',\n                     'ГОНОЧНЫЙ БОЛИД',\n                     'СМЗ',\n                     'DACIA',\n                     'SHANGHAI MAPLE',\n                     'DADI',\n                     'ГАЗ',\n                     'JMC',\n                     'HAFEI',\n                     'ЛУАЗ',\n                     'OLDSMOBILE',\n                     'МОСКВИЧ',\n                     'AC',\n                     'EXCALIBUR',\n                     'EAGLE',\n                     'ИЖ',\n                     'MITSUOKA',\n                     'ЗАЗ',\n                     'METROCAB',\n                     'DALLARA',\n                     'GMC',\n                     'FOTON',\n                     'LINCOLN',\n                     'HAWTAI',\n                     'ZX',\n                     'DONGFENG',\n                     'AMC',\n                     'TATRA',\n                     'DS',\n                     'PUCH',\n                     'ISUZU',\n                     'MAYBACH',\n                     'PONTIAC',\n                     'DERWAYS',\n                     'ROVER',\n                     'ASIA',\n                     'HAIMA',\n                     'MERCURY',\n                     'ALFA ROMEO',\n                     'BUICK',\n                     'DAIHATSU',\n                     'PLYMOUTH',\n                     'BYD',\n                     'MG',\n                     'ASTON MARTIN',\n                     'FIAT',\n                     'SAAB',\n                     'JAC',\n                     'LADA (ВАЗ)',\n                     'ARIEL',\n                     'SATURN',\n                     'DODGE',\n                     'CHRYSLER',\n                     'УАЗ',\n                     'ТАГАЗ',\n                     'BRILLIANCE',\n                     'ЗИЛ',\n                     'HUMMER',\n                     'ALPINA',\n                     'LANCIA',\n                     'LAMBORGHINI',\n                     'SCION',\n                     'DAEWOO',\n                     'TRIUMPH',\n                     'VORTEX',\n                     'FAW']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отфильтруем из данных \"плохие брэнды\"\ndata = data[~data.brand.isin(bad_mape_brands)]\n\n# И брэнды где записей меньше 100\ndata = data.groupby('brand').filter(lambda x: len(x) > 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['car_url', 'image', 'priceCurrency', 'ownage', 'sell_id', 'complectation_dict', \n                 'parsing_unixtime', 'model_info', 'health', 'custom', 'super_gen', 'description', 'equipment_dict']\n\n# Catergory columns\ncat_cols = ['model_name', 'name', 'brand', 'color', 'bodyType', 'gear_type',\n                            'vehicleTransmission', 'vendor', 'vehicleConfiguration', 'owners',\n                            'numberOfDoors', 'pts', 'wheeldrive', 'fuelType']\n\n\nprocessing_pipe = make_pipeline(DatasetProcessing(cat_boost_prepare=True, use_log=True, target_encode=True),\n                                DatasetFE(ohe=False, use_equip=True), \n                                FeatureGenerator(feature_list=['mileage', 'engineDisplacement_log', 'enginePower_log'],\n                                                                            primitives='all'), FeatureEraser(drop_cols))\n\nX, y, X_sub = prepare_data_pipeline(data, processing_pipe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраним незакодированные данные для анализа моделей\norig_cats = pd.DataFrame()\norig_cats = data.iloc[X.index, [0, 1, 3, 9, 14, 15, 16, 22, 23, 24, 25, 28]]\n\n# # TargetEncode\ntarget_encoder = ce.TargetEncoder(cols=cat_cols, smoothing=5).fit(X,y)\nX = target_encoder.transform(X)\nX_sub = target_encoder.transform(X_sub)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Модель для отбора признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Наша модель для отбора фич\n# def cat_model(X_train, X_test, y_train, y_test):\n#     model = CatBoostRegressor(iterations = 20000,\n#                               learning_rate = 0.1,\n#                               random_seed = RANDOM_SEED,\n#                               eval_metric='MAPE',\n#                               custom_metric=['R2', 'MAE'],\n#                                od_type='Iter',\n#                                od_wait=600,\n#                               #max_ctr_complexity=1\n#                              )\n\n#     model.fit(X_train, y_train,\n#              #cat_features=cat_features_ids,\n#              eval_set=(X_test, y_test),\n#              verbose_eval=500,\n#              use_best_model=True,\n#              plot=False,\n#              )\n    \n#     return(model)\n\n# subs_cat_fs, feature_importance_df, oof_fs = run_model_cv(cat_model, X=X, y=y, sub_test=X_sub, cv=5, \n#                            random_state=RANDOM_SEED, name='catboost_fe_fs', comment=\"\")\ndef et_model(X_train, X_test, y_train, y_test):\n    # Create a based model\n    rf = ExtraTreesRegressor(n_jobs=-1, random_state=RANDOM_SEED, n_estimators=100)\n    rf.fit(X_train, y_train)\n\n    return (rf)\n\n# # RFE FEATURE SELECTION\n# select_estimator = ExtraTreesRegressor(n_jobs=-1, random_state=RANDOM_SEED, n_estimators=50)\n# selector = RFE(select_estimator, n_features_to_select=100, step=10, verbose=1)\n# selector = selector.fit(X, y)\n# selector.support_\n\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rfe_cols = X.columns[selector.support_]\n\n# FEATURE IMPORTANCE\nsubs_et_fs, feature_importance_df, oof_etfs_predicts = run_model_cv(et_model, X=X, y=y, sub_test=X_sub, cv=5, random_state=RANDOM_SEED, name='etree_default')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 100)\n\n# Ограничим количество фич\nfeature_limit = 100\n\n# возьмем среднее значение важности фич из KFold\nall_features = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\nall_features.reset_index(inplace=True)\nimportant_features = list(all_features[:feature_limit]['feature'])\nall_features[:feature_limit]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим корреляцию фич\ndf = X[important_features]\ncorr_matrix = X.corr().abs()\n\n# Верхний треугольник матрицы корреляций\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Индекс фич с корреляцией выше 0.95\nhigh_cor = [column for column in upper.columns if any(upper[column] > 0.95)]\nprint(len(high_cor))\nprint(high_cor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем сильно коррелирующией между собой фичи\nfeatures = [i for i in important_features if i not in high_cor]\nprint(len(features))\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL\n### CatBoost Basemodel"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим как обучается базовая модель\nX_train, X_test, y_train, y_test = train_test_split(X[features], y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)\n\ndef cat_model(X_train, X_test, y_train, y_test):\n    model = CatBoostRegressor(iterations = 20000,\n                              learning_rate = 0.05,\n                              random_seed = RANDOM_SEED,\n                              eval_metric='MAPE',\n                              custom_metric=['R2', 'MAE'],\n                              od_type='Iter',\n                              od_wait=150,\n                             #'logging_level': 'Silent',\n                              #max_ctr_complexity=1\n                             )\n\n    model.fit(X_train, y_train,\n             #cat_features=cat_features_ids,\n             eval_set=(X_test, y_test),\n             verbose_eval=500,\n             use_best_model=True,\n             plot=False,\n             )\n    \n    return(model)\n\n#base_cat_model = cat_model(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CatBoostCV\nsub_cat, feature_importances_df, oof_cat_predicts = run_model_cv(cat_model, X=X.loc[:, :], y=y, sub_test=X_sub.loc[:, :], cv=5, \n                           random_state=RANDOM_SEED, name='catboost_fe_11', comment=\"t_enc\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance SHAPley"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\n# Разобьтем трэйн\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, random_state=RANDOM_SEED)\n\n\nmodel = cat_model(X_train, X_test, y_train, y_test)\nshap_values = model.get_feature_importance(Pool(X_test, label=y_test), \n                                                                     type=\"ShapValues\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expected_value = shap_values[0,-1]\nshap_values_ = shap_values[:,:-1]\n\nshap.initjs()\nshap.force_plot(expected_value, shap_values_[77,:], X_test.iloc[77,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DTREE"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dt_model(X_train, X_test, y_train, y_test):\n    # Create a based model\n    dt = DecisionTreeRegressor(random_state=RANDOM_SEED)\n    dt.fit(X_train, y_train)\n\n    return (dt)\n\nbase_dt_tree = dt_model(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Запускаем модель CV\nsub_dt, fi, oof_df_predicts = run_model_cv(dt_model, X=X.loc[:, features], y=y, sub_test=X_sub.loc[:, features], cv=5, random_state=RANDOM_SEED, name='rf_cv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_params = {  'max_depth': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, None],\n                 'max_features': ['auto', 'sqrt'],\n                 'min_samples_leaf': [1, 2, 4],\n                 'min_samples_split': [2, 5, 10],\n                 'n_estimators': [10, 50, 100]}\n\ndef rf_model(X_train, X_test, y_train, y_test):\n    # Create a based model\n    rf = RandomForestRegressor(n_jobs=-1, random_state=RANDOM_SEED, n_estimators=100)\n    rf.fit(X_train, y_train)\n\n    return (rf)\n    \n#base_rf_model = rf_model(X_train, X_test, y_train, y_test)\nmape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\nrnd_clf = RandomizedSearchCV(RandomForestRegressor(), scoring=mape_scorer, cv=3, param_distributions=grid_params, n_jobs=-1, verbose=1)\nrnd_clf.fit(X_train, y_train)\nprint(rnd_clf.best_params_)\nprint(f'Best score: {rnd_clf.best_score_}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = rnd_clf.best_estimator_\nX_test.drop(['dummy_armored', 'dummy_U25'], axis=1, inplace=True)\nX_train.drop(['dummy_armored', 'dummy_U25'], axis=1, inplace=True)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(rf, random_state=RANDOM_SEED).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LIME\nexplainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=['CarPrice'], verbose=True, mode='regression')\nexp = explainer.explain_instance(X_test.values[27], rf.predict, num_features=10)\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.iloc[X_test.iloc[27].name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Запускаем модель CV\nsub_rf, fi, oof_rf_predicts = run_model_cv(rf_model, X=X.loc[:, features], y=y, sub_test=X_sub.loc[:, features], cv=5, random_state=RANDOM_SEED, name='rf_cv', target_encoding=True, te_cols=cat_cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ExtraTree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"def et_model(X_train, X_test, y_train, y_test):\n    # Create a based model\n    rf = ExtraTreesRegressor(n_jobs=-1, random_state=RANDOM_SEED, n_estimators=100)\n    rf.fit(X_train, y_train)\n\n    return (rf)\n\n# Базовая модель\nbase_et_model = et_model(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ET CV\nsubs_et, fi, oof_et_predicts = run_model_cv(et_model, X=X.loc[:, features], y=y, sub_test=X_sub.loc[:, features], cv=5, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGBM\ndef lgbm_model(X_train, X_test, y_train, y_test):\n    # LGBM\n    lgbm_model = LGBMRegressor(objective='regression',\n                              num_leaves=4,\n                              learning_rate=0.1, \n                              n_estimators=5000,\n                              max_bin=75, \n                              bagging_fraction=0.8,\n                              bagging_freq=9, \n                              feature_fraction=0.45,\n                              feature_fraction_seed=9, \n                              bagging_seed=12,\n                              min_data_in_leaf=3, \n                              min_sum_hessian_in_leaf=2).fit(X_train, y_train, eval_set=(X_test, y_test), eval_metric='mape')\n\n    return (lgbm_model)\n\nbase_lgbm_model = lgbm_model(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGBM CV\nsubs_lgbm, fi, oof_lgbm_predicts = run_model_cv(lgbm_model, X=X.loc[:, :], y=y, sub_test=X_sub.loc[:, :], cv=5, random_state=RANDOM_SEED, name='lgbm', target_encoding=True, te_cols=cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_model(X_train, X_test, y_train, y_test):\n    xgb_reg = xgb.XGBRegressor(n_estimators=5000, learning_rate=0.1)\n    xgb_reg.fit(X_train, y_train, early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)], verbose=False)\n\n    return (xgb_reg)\n\nbase_xgb_model = xgb_model(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs_xgb, fi, oof_xgb_predicts = run_model_cv(xgb_model, X=X.loc[:, :], y=y, sub_test=X_sub.loc[:, :], cv=5, random_state=RANDOM_SEED, name='xgb')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bagging"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bagging_model(X_train, X_test, y_train, y_test):\n    # Create a based model\n    bagging_clf = BaggingRegressor(DecisionTreeRegressor(random_state=RANDOM_SEED), n_jobs=-1, n_estimators=200)\n    bagging_clf.fit(X_train, y_train)\n\n    return (bagging_clf)\n\nsubs_bagging, fi = run_model_cv(bagging_model, X=X.loc[:, features], y=y, sub_test=X_sub.loc[:, features], cv=5, random_state=RANDOM_SEED, name='bagging', model_type='bagging')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report = show_models_report()\nreport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge Submissions\ndef average_submission(*args, k=0.95):\n    sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n\n    subs = np.zeros_like(args[0])\n    for submission in args:\n        subs += submission / len(args)\n\n    subs['blend'] = (subs.sum(axis=1))/len(subs.columns)*k\n    sample_submission['price'] = round_preds(subs['blend'].values)\n    sample_submission.to_csv(f'submission_blend_v{VERSION}.csv', index=False)\n        \n    return sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# StackingModels\nk = 0.95\n\nX_train_oof = pd.DataFrame(np.c_[oof_et_predicts, oof_rf_predicts], columns=['et', 'rf'])\nX_test_oof = pd.DataFrame(np.c_[subs_et.mean(axis=1)*k, sub_rf.mean(axis=1)*k], columns=['et', 'rf'])\n\n\n# MetaModel\ndef meta_model(X_train, y_train):\n    # Create a based model\n    meta = Ridge()\n    meta.fit(X_train, y_train)\n\n    return (meta)\n\nmeta_clf = meta_model(X_train_oof, y.values)\nsubs = meta_clf.predict(X_test_oof)\n\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\nsample_submission['price'] = subs\nsample_submission.to_csv(f'submission_stack_v{VERSION}.csv', index=False)\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = average_submission(sub_cat)\nsample_submission.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Разберем ошибки моделей"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предикты моделей\nselected_columns = X.columns.str.contains('dummy_')\npredicts_df = pd.DataFrame(np.c_[oof_etfs_predicts, oof_cat_predicts], columns=['price_ET', 'price_CAT'])\nmodel_error_df = pd.concat([X[X.columns[~selected_columns]].reset_index(drop=True), y.reset_index(drop=True), predicts_df], axis=1)\n\n# Столбцы с MAPE\nmodel_error_df['mape_et'] = mape_per_row(model_error_df.price, model_error_df.price_ET)\nmodel_error_df['mape_cat'] = mape_per_row(model_error_df.price, model_error_df.price_CAT)\nmodel_error_df['mape_mean'] = (model_error_df['mape_et'] + model_error_df['mape_cat']) / 2\n\ncolumns_rename = {'Владельцы': 'owners', 'Владение': 'ownage', 'ПТС': 'pts', 'Привод': 'gear_type', 'Руль': 'wheeldrive', 'Состояние': 'health', 'Таможня': 'custom'}                \norig_cats.rename(columns=columns_rename, inplace=True)\n\nmodel_error_df[orig_cats.drop(['owners'], axis=1).columns] = orig_cats.drop(['owners'], axis=1).reset_index(drop=True)\nmodel_error_df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Общее количество записей с высокой ошибкой [11576, 11511]\nprint(f'Общее количество предсказаний с высоким MAPE: {model_error_df[model_error_df.mape_mean > 20].brand.count()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмортим на MAPE по маркам (отфильтрованы \"плохие брэнды\")\nbrand_mape = plot_feature_by_avg_target(model_error_df, 'brand', target='mape_cat', plot=True, title='MAPE (CAT)')\nbrand_mape = plot_feature_by_avg_target(model_error_df, 'brand', target='mape_et', plot=True, title='MAPE (ExtraTree)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Предварительно были отфильтрованы марки авто, на которых был очень высокий MAPE.**\n1. Модели ошибаются на марке PROTON, а ET ошибается на HUANGHAI. Кандидаты на удаление из выборки.\n2. На втором этапе видно, что много ошибок FERRARI, DW, DATSUN, IVECO, LIFAN, MASERATI, MCLAREN, TESLA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмортим на MAPE по типу топлива\nplot_feature_by_avg_target(model_error_df, 'fuelType', target='mape_cat', plot=True, title='MAPE (CAT)')\nplot_feature_by_avg_target(model_error_df, 'fuelType', target='mape_et', plot=True, title='MAPE (ExtraTree)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Выше всего ошибка на электрокарах. Обе модели показывают одинаковые результаты."},{"metadata":{"trusted":true},"cell_type":"code","source":"# TestBrand MAPE\ntest_brands = ['BMW',\n 'VOLKSWAGEN',\n 'NISSAN',\n 'MERCEDES',\n 'TOYOTA',\n 'AUDI',\n 'MITSUBISHI',\n 'SKODA',\n 'VOLVO',\n 'HONDA',\n 'INFINITI',\n 'LEXUS']\n\n# Наши тестовые марки\nplot_feature_by_avg_target(model_error_df[model_error_df.brand.isin(test_brands)], 'brand', target='mape_cat', plot=True, title='MAPE (CAT)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand.isin(test_brands)], 'brand', target='mape_et', plot=True, title='MAPE (ExtraTree)')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, хуже всего модели предсказывают Японские брэнды. Нужно с этим разобраться."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим по типу корпуса по худшим маркам\n# HONDA\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'TOYOTA'], 'model_name', target='mape_cat', plot=True, title='MAPE (Cat)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'TOYOTA'], 'bodyType', target='mape_cat', plot=True, title='MAPE (Cat)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'TOYOTA'], 'model_name', target='mape_et', plot=True, title='MAPE (ET)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'TOYOTA'], 'bodyType', target='mape_et', plot=True, title='MAPE (ET)')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# TOYOTA\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'HONDA'], 'model_name', target='mape_cat', plot=True, title='MAPE (Cat)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'HONDA'], 'bodyType', target='mape_cat', plot=True, title='MAPE (Cat)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'HONDA'], 'model_name', target='mape_et', plot=True, title='MAPE (ET)')\nplot_feature_by_avg_target(model_error_df[model_error_df.brand == 'HONDA'], 'bodyType', target='mape_et', plot=True, title='MAPE (ET)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отберем худшие предсказания моделей HONDA TOYOTA\nfilter_worst = np.where((model_error_df.brand.isin(['TOYOTA', 'HONDA'])) & (model_error_df.mape_mean > 20))\nworst_brands = model_error_df.iloc[filter_worst]\n\n\nworst_brands.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values = base_cat_model.get_feature_importance(Pool(X, label=y), \n                                                                      type=\"ShapValues\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expected_value = shap_values[0,-1]\nshap_values_ = shap_values[:,:-1]\n\nshap.initjs()\nshap.force_plot(expected_value, shap_values_[19475,:], X.iloc[19475,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_, X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_error_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"5.547823e+05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_error_df.groupby('brand').color.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}